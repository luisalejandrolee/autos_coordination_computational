{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Main file\n",
    "This main file is based on the scripts that I had for minimizing the machines from Netlogo. The original was made to capture output from Behaviour Space, processs the machines and then print it to use in Stata. This is too cumbersome, so decided to implement and do everything in Python so I can centralise all the analysis and work on the next algorithms such as Joint Machines, frequencies and unused behavioural states in order to analyse properly how the transitions are happening."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#1 Receiving the Netlogo output\n",
    "The first step is to load the files. Also, as the global variables of interest in order to associate it with the output name file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import random\n",
    "from __future__ import division\n",
    "from __future__ import with_statement\n",
    "import platform\n",
    "import datetime\n",
    "import minimization as minz #My script in same folder for minimization routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#GLOBALS: choose\n",
    "#Make sure the files exist (i.e. from Netlogo simulations)\n",
    "experiment_clue = \"signalcesuperlong2\"#signalcesuperlong1\n",
    "output_file_modifier='' #To change the name of output file\n",
    "n_states = 8\n",
    "n_signals = 1 #only without signal for now\n",
    "n_rounds = 50\n",
    "N = 40\n",
    "n_parents = 20\n",
    "\n",
    "#Choose generations to load (\"None\" to import the whole file)\n",
    "start_gen=54000\n",
    "number_of_gens=2 #So final generation imported is start_gen+number_of_gens-1\n",
    "\n",
    "#PDF parameters\n",
    "coin_throws = 50\n",
    "restarts = 10\n",
    "\n",
    "#Epochs classification parameters\n",
    "regime_threshold = 50 #for epoch by jm\n",
    "\n",
    "epoch_window = 10 #lagged regimes to be considered\n",
    "epoch_tolerance = 3 #number of misses in the window before breaking an epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Equivalent of generations in the strategies file\n",
    "total_pop=N*2 #total number of autos per generation\n",
    "start_row_strat=(start_gen*total_pop if start_gen!=None else None)\n",
    "number_rows_strat=(number_of_gens*total_pop if number_of_gens!=None else None)\n",
    "\n",
    "\n",
    "globals_list = (experiment_clue, n_states, n_signals, n_rounds, N, n_parents) #Save them as a list\n",
    "\n",
    "#Experiment name based on the chosen experiment_clue and globals\n",
    "chosen_experiment = \"%s_states_%s_signal_%s_rounds_%s_N_%s_parents_%s.txt\" % globals_list\n",
    "\n",
    "#Both files have to use the same \"chosen experiment\" (to make sure come from the same simulation in Netlogo)\n",
    "summary_file_name = \"summary_\" + chosen_experiment #Summary output\n",
    "strategies_file_name = \"strategies_\" + chosen_experiment #Strategies output\n",
    "\n",
    "#Path to Netlogo outputs\n",
    "netlogo_folder = \"/Users/luisalejandrolee/Dropbox/Thesis Phd/\\\n",
    "Coordination autos Chapter three/outputs_from_netlogo/\" #Netlogo outputs in this folder\n",
    "\n",
    "if platform.system()=='Windows':\n",
    "    netlogo_folder = 'C:\\\\Users\\\\lexlale\\\\Dropbox\\\\Thesis Phd\\\\Coordination autos Chapter three\\\\outputs_from_netlogo\\\\'\n",
    "\n",
    "#Get the first line as header (for when importing only some generations instead of the whole file)\n",
    "with open(netlogo_folder+summary_file_name, 'r') as f:\n",
    "    line_s = f.readline()\n",
    "    line_s = line_s.split(',')\n",
    "    line_s[len(line_s)-1]=line_s[len(line_s)-1].replace('\\n','')#Delete last special carachter \"\\n\"\n",
    "#For the strategies file\n",
    "with open(netlogo_folder+strategies_file_name, 'r') as f:\n",
    "    line_st = f.readline()\n",
    "    line_st = line_st.split(',')\n",
    "    line_st[len(line_st)-1]=line_st[len(line_st)-1].replace('\\n','')\n",
    "    \n",
    "#Read files and save them as data\n",
    "df_sum = pd.read_csv(netlogo_folder + summary_file_name,\\\n",
    "                     skiprows=start_gen,nrows=number_of_gens)\n",
    "\n",
    "df_strat = pd.read_csv(netlogo_folder + strategies_file_name,\\\n",
    "                       skiprows=start_row_strat,nrows=number_rows_strat)\n",
    "#Replace header using first row of file (instead of from imported data)\n",
    "df_sum.columns=line_s\n",
    "df_strat.columns=line_st\n",
    "\n",
    "summary = df_sum.copy() #allows to go directly to regime characterization by average (without joint machines)\n",
    "init_time = datetime.datetime.time(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#2 Minimise the automata\n",
    "Use the functions to have a simple code here for minimising the auto and storing other relevant variables (as available states, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Other required globals\n",
    "n_obs = 2 if n_signals == 0 else 4 #Define here (or change) the possible observations of the machines\n",
    "\n",
    "canon_autos_list = [] #Create empty lists to store the processed autos below\n",
    "min_autos_list = []\n",
    "\n",
    "\n",
    "for i in df_strat.index: #For each row...\n",
    "    netlogo_auto = df_strat.auto_long[i] #... for all netlogo_auto\n",
    "    big_auto = minz.to_format_netlogo_auto(netlogo_auto) #Use function to convert the raw Netlogo auto in a list format\n",
    "    init_state = big_auto[0] #Save initial state of the machine\n",
    "    normal_auto = minz.new_empty_auto(n_obs, n_states) #Use function to create a new empty auto as a numpy array\n",
    "\n",
    "    # Next block it to fill the new 'normal_auto' with the information from big_auto.\n",
    "    # The objective is that normal_auto=big_auto but as an array (instead of a list)\n",
    "    my_index = xrange(1, len(big_auto), n_obs + 1) # Each number in the index is where a state starts\n",
    "    for i, j in enumerate(my_index):\n",
    "        normal_auto['actions'][i] = big_auto[j]\n",
    "        normal_auto['transitions'][i] = big_auto[j + 1:j + n_obs + 1]\n",
    "        \n",
    "    canon_auto = minz.convert_to_canonical(normal_auto, n_states, init_state, n_obs) #Use function for canonical form\n",
    "    \n",
    "    access_states = len(canon_auto) #n_states now is only the accesible states of the machine (before minimization)\n",
    "    \n",
    "    #Use function to get minimum behavioural equivalent auto\n",
    "    #Passes \"0\" as 3rd argument because that's init_state now (always 0 for canonical auto)\n",
    "    min_auto = minz.minimized_automaton(canon_auto, access_states, 0, n_obs)\n",
    "    \n",
    "    #Update autos lists\n",
    "    canon_autos_list.append(canon_auto) #Store proccessed autos in the corresponding list\n",
    "    min_autos_list.append(min_auto)\n",
    "    \n",
    "#Add the processed autos lists as columns to df_strat\n",
    "df_strat[\"canon_autos\"] = canon_autos_list #Add the lists with autos to the dataframe\n",
    "df_strat[\"min_autos\"] = min_autos_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#3 Accesible states and minimum behavioural states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "access_states = [len(x) for x in df_strat.canon_autos] #accesible states in the big machine\n",
    "min_states = [len(x) for x in df_strat.min_autos] #accesible states in the minimized machine\n",
    "\n",
    "df_strat[\"access_states\"] = access_states\n",
    "df_strat[\"min_states\"] = min_states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#4 Joint machines (not minimized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Lists to keep track of joint machines\n",
    "gen_list = []\n",
    "jm_list = []\n",
    "parents_index_list = []\n",
    "for gen in df_sum.generation: #each generation\n",
    "    df_col = df_strat[(df_strat.population == \"column\") & (df_strat.generation == gen)][:] #column autos for this gen\n",
    "    df_row = df_strat[(df_strat.population == \"row\") & (df_strat.generation == gen)][:] #row autos for this gen\n",
    "    \n",
    "    for i0, auto0 in enumerate(df_col.min_autos):#minimized autos in population col, for this gen\n",
    "        index_0=df_col.index[i0]\n",
    "        \n",
    "        for i1, auto1 in enumerate(df_row.min_autos):#minimized autos in population row, for this gen\n",
    "            index_1=df_row.index[i1]\n",
    "            \n",
    "            if n_signals==1: #With signal\n",
    "                jm = minz.create_joint_machine_with_signal(auto0, auto1) #Function to create the joint machine\n",
    "            if n_signals==0: #No signal\n",
    "                jm = minz.create_joint_machine_no_signal(auto0, auto1) #Function to create the joint machine\n",
    "            \n",
    "            gen_list.append(gen) #Keeps track of generation\n",
    "            jm_list.append(jm)   #Keeps track of joint machines\n",
    "            #Parents_index_list Keeps track of joint machine constituent machines' location (index) in df_strat\n",
    "            parents_index_list.append([index_0, index_1]) #Needed for Unused states measure\n",
    "            \n",
    "#Store the joint machines, generation and parent index (in a new dataframe)\n",
    "df_jms = pd.DataFrame(columns = (\"generation\", \"jm\", \"parents_index\")) #Store joint machines with associated generation\n",
    "df_jms.generation = gen_list\n",
    "df_jms.jm = jm_list\n",
    "df_jms.parents_index = parents_index_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#5 Minimize the joint machines \n",
    "Adds the 'min_jm' column to df_jms (tuples with the minimized joint machines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "min_jm_list = [] #to save the minimized joint machines, and add later to the dataframe (df_jms)\n",
    "\n",
    "for i, jm in enumerate(df_jms.jm): #all joint machines\n",
    "#for jm in [df_jms.jm[24000], df_jms.jm[24001]]:\n",
    "\n",
    "    if n_signals==1:#with signal\n",
    "        canon_jm = minz.convert_to_canonical(jm, len(jm), 0, 2)\n",
    "        min_jm = minz.minimized_automaton(canon_jm, len(canon_jm), 0, 2)\n",
    "\n",
    "        #Next lines convert the min_jms, which is a dict, into a tuple\n",
    "        #Converts an structured numpy array (\"actions\" and 'transitions' in the min_jm)into a tuple of tuples\n",
    "        #This is so that it can be used as a key to use groupby (since tuple is inmutable)\n",
    "        tup_transitions = tuple(tuple(pair_transitions) for pair_transitions in min_jm[\"transitions\"])\n",
    "        tup_actions = tuple(min_jm['actions'])\n",
    "        min_jm = tuple(zip(tup_actions,tup_transitions))\n",
    "    \n",
    "    if n_signals==0:#no signal\n",
    "        #print 'jm = ',jm\n",
    "        min_jm = minz.minimize_joint_machine_no_signal(jm) #minimize them (have actions and cyclestart)\n",
    "        #print 'minimized_jm = ',min_jm,'\\n'\n",
    "        #Next lines convert the min_jms, which is a dict, into a tuple\n",
    "        #Converts a list of lists (\"actions\" in the min_jm)into a tuple of tuples\n",
    "        #This is so that it can be used as a key to use groupby (since tuple is inmutable)\n",
    "        tup_actions = tuple(tuple(pair_actions) for pair_actions in min_jm[\"actions\"]) #convert actions to tuples\n",
    "        min_jm = (tup_actions, min_jm[\"cyclestart\"]) #add the cyclestart to final min_jm tuple        \n",
    "    \n",
    "\n",
    "    min_jm_list.append(min_jm) #save the minimized machine to a list\n",
    "\n",
    "# Save the minimized joint machines\n",
    "df_jms[\"min_jms\"] = None #new empty column in dataframe\n",
    "df_jms.min_jms = min_jm_list #add the minimized joint machines to the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Probability Density Function for not minimized joint machines (with signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#if n_signals == 0:\n",
    "#    pass\n",
    "\n",
    "if n_signals == 1:\n",
    "    pdf_list = [] #to save the pdf of each joint machine and add later to the dataframe (df_jms)\n",
    "    \n",
    "    for i,jm in enumerate(df_jms.jm):\n",
    "        #Here jm is the joint machine (not minimized), followed by the number of signals to feed the machine with,\n",
    "        #followed by the number of trials (repeats of feeding the signal). The total number of repetitions to obtain\n",
    "        #the PDF, is then tt*trials. Check the function in 'minimization'.\n",
    "        pdf = minz.prob_density_function_joint_machine_with_signal(jm,coin_throws,restarts)#arguments are auto, tt, trials\n",
    "        pdf_list.append(pdf)\n",
    "    \n",
    "    # Save the minimized joint machines\n",
    "    df_jms[\"pdf_long_jm\"] = pdf_list #new empty column in dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Used states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Prepare dataframe to keep track of unused states\n",
    "df_strat[\"used_states\"] = 0 # Will contain a list with states of each min_auto\n",
    "used_states_list = []\n",
    "for i, auto in enumerate(df_strat.min_autos): #all minimized autos\n",
    "    a = [0 for ix in xrange(df_strat.min_states[i])] #List the size of minimised machine's states\n",
    "    used_states_list.append(a)\n",
    "df_strat[\"used_states\"] = used_states_list #Add to dataframe\n",
    "\n",
    "\n",
    "if n_signals==0: #No signal\n",
    "    \n",
    "    for i,jm in enumerate(df_jms.jm): #all joint machines. They are not minimized.\n",
    "        index_0 = df_jms['parents_index'][i][0]#Index reference for parent machine (parents are in df_strat)\n",
    "        index_1 = df_jms['parents_index'][i][1]\n",
    "    \n",
    "    \n",
    "        for st in jm[\"states\"]: #for metastates in jointmachine\n",
    "            s0 = st[0] #state that is used by parent0 (stored in current metastate)\n",
    "            s1 = st[1]\n",
    "            #Go to the parent machine (in df_strat) and alter the 'used_states' list\n",
    "            df_strat[\"used_states\"][index_0][s0] = 1# =1 for states visited. Unvisited remain 0\n",
    "            df_strat[\"used_states\"][index_1][s1] = 1\n",
    "\n",
    "if n_signals==1: #with signal\n",
    "    \n",
    "    for i,jm in enumerate(df_jms.jm): #all joint machines. They are not minimized.\n",
    "        #The key here is that in the joint machines (in position 2 of each metastate) there is the information of\n",
    "        #the states used by each component machine. For example, if the joint machine's metastate 3 is formed by states\n",
    "        # 4 and 0 of parent0 and parent1, respectively, then jm[3][2]=[4,0]. So this information is contanined in \n",
    "        #the list 's', accesed when marking the used states (given by a positive probability in the pdf).\n",
    "        s = [x[2] for x in jm]\n",
    "        \n",
    "        index_0 = df_jms['parents_index'][i][0]#Index reference for parent machine (parents are in df_strat)\n",
    "        index_1 = df_jms['parents_index'][i][1]\n",
    "        #print 'jm index = ',i\n",
    "        #print 'index_0 = ',index_0\n",
    "        #print 'index_1 = ',index_1\n",
    "        \n",
    "        pdf = df_jms.pdf_long_jm[i] #pdf of the joint machine\n",
    "        used_jm_states_1 = [i if x[1]>0 else None for i,x in enumerate(pdf)] #has positions of used metastates (positive probability in pdf)\n",
    "        used_jm_states = [x for x in used_jm_states_1[:] if x!=None]#remove all \"None\" entries\n",
    "        #print 'used_jm_states',used_jm_states\n",
    "        \n",
    "        for st in used_jm_states: #all metastates with positive probability\n",
    "            parent0_state = s[st][0] #state used by parent0 in current used metastate\n",
    "            #print 'parent0_state = ',parent0_state\n",
    "            df_strat.used_states[index_0][parent0_state] = 1 #mark parent0's used states list (1=used, 0=unused)\n",
    "            #print 'parent0 used_state = ',df_strat.used_states[index_0]          \n",
    "            \n",
    "            #print 'current st = ',st\n",
    "            parent1_state = s[st][1]\n",
    "            #print 'parent1_state = ',parent1_state\n",
    "            df_strat.used_states[index_1][parent1_state] = 1\n",
    "            #print 'parent1 used_state = ',df_strat.used_states[index_1]    \n",
    "        #print \"\\n\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#6 Frequencies of minimized joint machines\n",
    "Outputs dataframe \"freqjm\" with frequencies of joint machines\n",
    "(Does it by transforming df_jms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Use Groupby and organize the data set for frequencies\n",
    "\n",
    "g1 = df_jms.copy() #use intermediate copies to avoid potential bugs later. Not sure if actually needed...\n",
    "g1 = g1.groupby([g1[\"generation\"], g1[\"min_jms\"]]) #split by groups\n",
    "g1 = g1.count() #organize as frequency of joint machine per generation\n",
    "\n",
    "interactions = N * N #number of joint machines per generation\n",
    "g1['freq_perc'] = [(x*100)/interactions for x in g1.jm] #frequency percentage of jm per generation\n",
    "\n",
    "\n",
    "#jm_freq_threshold = 0 #Change to higher for easier visualization\n",
    "#g1 = g1[g1.freq_perc > jm_freq_threshold] #keep machines with frequency higher than threshold\n",
    "\n",
    "\n",
    "#Organise the dataframe\n",
    "\n",
    "freqjm = g1.copy() #just in case...\n",
    "freqjm = freqjm.rename(columns = {'jm':'freq'}) #rename column\n",
    "freqjm = freqjm.reset_index() #reset_index converts the multiindex into normal columns (to use generation for 'sort')\n",
    "freqjm = freqjm.sort(['generation', 'freq_perc'], ascending=[True, False]) #sort\n",
    "\n",
    "\n",
    "#If no signal, show the lollipop machine as a string. Example: \"AA BB >>AA<<\"\" for a machines that plays first\n",
    "#AA, then BB, and then forever plays AA (whatever is inside >> << is the metamachine cycle)\n",
    "if n_signals==0:#no signal\n",
    "    freqjm['jm_show'] = [minz.min_jm_no_signal_to_string(x) for x in freqjm.min_jms] #use function to convert to string\n",
    "    freqjm['jm_cycle'] = [minz.find_between(jm,'>> ',' <<')\\\n",
    "                             for jm in freqjm['jm_show']] #Find the the cycle and print add it to dataframe for easier visualization\n",
    "    freqjm = freqjm.drop(['parents_index'],1)\n",
    "    \n",
    "#With signal, perhaps the jm_show (a good way to show the joint machine), is by using the Markov matrix\n",
    "if n_signals==1:#no signal\n",
    "    freqjm[\"pdf_min\"] = [minz.prob_density_function_joint_machine_with_signal(jm,coin_throws,restarts) for jm in freqjm.min_jms]\n",
    "    freqjm['pdf_cycle'] = [minz.get_high_pdf_states(i) for i in freqjm.pdf_min]\n",
    "    \n",
    "    \n",
    "    freqjm = freqjm.drop(['parents_index','pdf_long_jm'],1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#7 Unused behaviour and slack in construction measures\n",
    "\n",
    "Unused not ready for signal. Check later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Unused states: number of states not visited in the minimized machine\n",
    "unused_states = [len(x) - x.count(1) for x in df_strat.used_states] #unused states in min_autos\n",
    "\n",
    "#Unvisited: potential for novel behavior given change in the  input stream. Is unused states divided by min_states\n",
    "unvisited_measure = [(len(x)-x.count(1))/len(x) for x in df_strat.used_states]\n",
    "\n",
    "#Behaviour_slack: slack in the potential behavior of the machine\n",
    "#the more states you use, the more sophisticated you can become behaviorally.\n",
    "behaviour_slack = [len(x)/n_states for x in df_strat.min_autos] #min_lenght/total states.\n",
    "\n",
    "#construction_slack: slack in the construction of the complete machine\n",
    "construction_slack = [x/n_states for x in df_strat.access_states]#accesible/total\n",
    "\n",
    "df_strat['unused_states'] = unused_states\n",
    "df_strat['unvisited_measure'] = unvisited_measure    \n",
    "df_strat['behaviour_slack'] = behaviour_slack\n",
    "df_strat['construction_slack'] = construction_slack\n",
    "\n",
    "#df_strat = df_strat.drop('used_states', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Take the average per generation of unused states, unvisited measure, and slack measures\n",
    "\n",
    "strats = df_strat.copy() #just in case\n",
    "strats = strats.groupby(strats.generation).mean() #take the mean of all the variables (by generation)\n",
    "strats = strats.drop(['ID','score',],1) #not needed (1 is to drop columns instead of rows)\n",
    "strats = strats.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Take average of same measures, but per population\n",
    "\n",
    "strats_col = df_strat.copy()\n",
    "strats_col = strats_col[strats_col.population == 'column'] #choose only one population\n",
    "\n",
    "strats_row = df_strat.copy()\n",
    "strats_row = strats_row[strats_row.population == 'row']\n",
    "\n",
    "def change_columns_names(df, to_add): #changes the names of the columns of the datafrae, to add, for example, \"_row\"\n",
    "    old_names = df.columns\n",
    "    #change all names, expect 'generation'\n",
    "    new_names = [name+'%s'%to_add if name!='generation' else name for name in old_names[:]]\n",
    "    df.columns = new_names\n",
    "    return df\n",
    "\n",
    "strats_row = change_columns_names(strats_row, '_row')#use function to change column names\n",
    "strats_col = change_columns_names(strats_col, '_col')\n",
    "\n",
    "strats_row = strats_row.groupby(strats_row.generation).mean()#take mean of variables (per generation, per population)\n",
    "strats_col = strats_col.groupby(strats_col.generation).mean()\n",
    "\n",
    "strats_row = strats_row.reset_index() #organise index\n",
    "strats_col = strats_col.reset_index()\n",
    "\n",
    "to_delete_row = ['ID_row','score_row',' ce_individual_row']#drop some variables\n",
    "to_delete_col = ['ID_col','score_col',' ce_individual_col']#drop some variables\n",
    "strats_row = strats_row.drop(to_delete_row,1)\n",
    "strats_col = strats_col.drop(to_delete_col,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Organise summary dataframe, and include the measures calculated above.\n",
    "\n",
    "summary = df_sum.copy() #just in case\n",
    "#delete columns that won't use\n",
    "#to_delete = ['row_heads_A', 'row_heads_B', 'row_tails_A', 'row_tails_B', 'col_heads_A', 'col_heads_B',\\\n",
    "#'col_tails_A','col_tails_B','times_heads','times_tails']\n",
    "#summary = summary.drop(to_delete, axis=1)\n",
    "\n",
    "summary = pd.merge(summary, strats, on='generation') #merge datasets\n",
    "summary = pd.merge(summary, strats_row, on='generation')\n",
    "summary = pd.merge(summary, strats_col, on='generation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#8 Regime identification\n",
    "Two regime classifications: based on top joint machine and based on percentage of play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#By top joint machine:\n",
    "#Function to find the highest frequency percentage top machine\n",
    "def find_top_jm (df, n=1, column='freq_perc'):\n",
    "    return df.sort_index(by=column)[-n:]\n",
    "\n",
    "#Apply the function to get the highest frequency joint machine per generation\n",
    "topjm = freqjm.groupby('generation').apply(find_top_jm)\n",
    "\n",
    "#Define regime as the top joint machine in a generation if its frequency is above the defined \"regime_threshold\"\n",
    "#percentage (globals at the beginning of code. If none is above it, the regime is in \"other\"\n",
    "#regime_threshold = 50\n",
    "regime_jm = [jm if int(topjm.freq_perc[i]) > regime_threshold else 'not_threshold' for i,jm in enumerate(topjm.min_jms)]\n",
    "\n",
    "#Add regime to summary dataframe\n",
    "summary['regime_jm'] = regime_jm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#By percentage:\n",
    "regime_av = [None for i in summary.index] #Create variable to fill\n",
    "\n",
    "#Regime based on percetanges of machines playing AA or BB\n",
    "for i in summary.index: #all generations\n",
    "    \n",
    "    A = summary.coordination_A_perc[i] #percentage of AA plays for this generation\n",
    "    B = summary.coordination_B_perc[i] #percentage of BB plays for this generation\n",
    "    \n",
    "    if A > 0.8:\n",
    "        regime_av[i] = 'Domination_AA'\n",
    "    elif B > 0.8:\n",
    "        regime_av[i] = 'Domination_BB'\n",
    "    elif A > 0.35 and A < 0.55 and B > 0.35 and B < 0.55:\n",
    "        regime_av[i] = 'Turn_Taking'\n",
    "    elif A > 0.5 and A < 0.8 and B > 0.2 and B < 0.5:\n",
    "        regime_av[i] = 'Biased_Turn_A'\n",
    "    elif B > 0.5 and B < 0.8 and A > 0.2 and A < 0.5:\n",
    "        regime_av[i] = 'Biased_Turn_B'\n",
    "    else:\n",
    "        regime_av[i] = 'Other'\n",
    "        \n",
    "summary['regime_av'] = regime_av  \n",
    "#summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#9 Epoch characterization\n",
    "Two Epoch matrices are constructed: \"epoch_av\", with epochs based on the average percentage of AA and BB per generation (computationally much faster and doesn't require previous procedures but only the summary matrix), and \"epoch_jm\" which is based on the top machine of the generation\n",
    "\n",
    "An epoch is defined as having the top joint machine on a generation (i.e. regime) to be the same over a window of \n",
    "past generations (e.g. was this period the same regime as in the past ones?). In that window of past regimes, some tolerance is permitted (i.e. some of them can be different, allowing for some errors).\n",
    "\n",
    "The algorithm considers an epoch to have started when a regime appears a minimum number of times in the window of past regimes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Epoch characterization works well with 10 and 3 for long simulations\n",
    "#epoch_window = 10 #lagged regimes to be considered\n",
    "#epoch_tolerance = 3 #number of misses in the window before breaking an epoch\n",
    "\n",
    "#Use custom function to generate epoch matrix\n",
    "epochs_av=minz.epoch_matrix(summary,'regime_av',epoch_window,epoch_tolerance) #based on average percentages of (AA,BB)\n",
    "#print epochs_av"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Requires Joint Machines\n",
    "\n",
    "epochs_jm=minz.epoch_matrix(summary,'regime_jm',epoch_window,epoch_tolerance) #based on top joint machine\n",
    "\n",
    "#Add string and cycle for easy visualization\n",
    "if n_signals==0:\n",
    "    #String of the machine\n",
    "    epochs_jm['jm_show'] = [minz.min_jm_no_signal_to_string(x)\\\n",
    "               if x!='not_threshold' else 'not_threshold 'for x in epochs_jm.epoch]\n",
    "    \n",
    "    #Just the cycle\n",
    "    epochs_jm['jm_cycle'] = [minz.find_between(x,'>> ',' <<')\\\n",
    "                             for x in epochs_jm['jm_show']] #Find the the cycle and print add it to dataframe for easier visualization\n",
    "\n",
    "if n_signals == 1:\n",
    "    #Add pdf of the machine\n",
    "    epochs_jm[\"pdf\"] = [minz.prob_density_function_joint_machine_with_signal(jm,coin_throws,restarts)\\\n",
    "               if x!='not_threshold' else 'not_threshold' for x in epochs_jm.epoch]\n",
    "    epochs_jm['pdf_cycle'] = [minz.get_high_pdf_states(i)\\\n",
    "                             if i!='not_threshold' else 'not_threshold' for i in epochs_jm.pdf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number_of_gens =  2\n",
      "init_time =  02:17:51.729405\n",
      "end_time =  02:18:32.021059\n"
     ]
    }
   ],
   "source": [
    "end_time = datetime.datetime.time(datetime.datetime.now())\n",
    "print 'number_of_gens = ',number_of_gens\n",
    "print 'init_time = ',init_time\n",
    "print 'end_time = ',end_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#WARNING: NEXT IS PRINTING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#10 Export main dataframes\n",
    "Export the three main data frames, so I can work with graphs and statistics from a different file. This makes the scripts a bit more modular, and also I just have to run the minimization procedures (this file) only once per experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#output_file_modifier='' #To change the name of output file\n",
    "\n",
    "#Path to python outputs\n",
    "python_folder = \"/Users/luisalejandrolee/Dropbox/Thesis Phd/\\\n",
    "Coordination autos Chapter three/outputs_from_python/\" #Netlogo outputs in this folder\n",
    "\n",
    "if platform.system()=='Windows':\n",
    "    python_folder = 'C:\\\\Users\\\\lexlale\\\\Dropbox\\\\Thesis Phd\\\\Coordination autos Chapter three\\\\outputs_from_python\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Based on percentage of plays (AA and BB)\n",
    "epochs_av.to_csv((python_folder+'epochs_av_'+output_file_modifier+chosen_experiment))\n",
    "\n",
    "#summary: contains main variables. Averages per generation\n",
    "summary.to_csv(python_folder+'summary_'+output_file_modifier+chosen_experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#freqjm: frequency of each joint machine per generation.\n",
    "freqjm.to_csv(python_folder+'jm_'+output_file_modifier+chosen_experiment)\n",
    "\n",
    "#epochs: each row has the regime \n",
    "#Top joint machine (if above threshold, otherwise \"not_threshold\")\n",
    "epochs_jm.to_csv((python_folder+'epochs_jm_'+output_file_modifier+chosen_experiment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#WARNING! no need to run the script further\n",
    "###Just for visualization\n",
    "freqjm: frequency of all joint machines per generation (for transition analysis)\n",
    "\n",
    "summary: main variables (averages per generation)\n",
    "\n",
    "epochs: classification of epochs, with duration, starting and ending periods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>generation</th>\n",
       "      <th>min_jms</th>\n",
       "      <th>freq</th>\n",
       "      <th>freq_perc</th>\n",
       "      <th>pdf_min</th>\n",
       "      <th>pdf_cycle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>54000</td>\n",
       "      <td>((AB, (1, 3)), (BA, (2, 2)), (AA, (3, 3)), (BB...</td>\n",
       "      <td>476</td>\n",
       "      <td>29.7500</td>\n",
       "      <td>[(AB, 0.02), (BA, 0.01), (AA, 0.326), (BB, 0.6...</td>\n",
       "      <td>[(AA, 0.326), (BB, 0.644)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>54000</td>\n",
       "      <td>((AB, (1, 3)), (AA, (2, 2)), (BB, (2, 1)), (AB...</td>\n",
       "      <td>160</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>[(AB, 0.02), (AA, 0.316), (BB, 0.658), (AB, 0....</td>\n",
       "      <td>[(AA, 0.316), (BB, 0.658)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>54001</td>\n",
       "      <td>((AB, (1, 3)), (BA, (2, 2)), (AA, (3, 3)), (BB...</td>\n",
       "      <td>375</td>\n",
       "      <td>23.4375</td>\n",
       "      <td>[(AB, 0.02), (BA, 0.016), (AA, 0.338), (BB, 0....</td>\n",
       "      <td>[(AA, 0.338), (BB, 0.626)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>54001</td>\n",
       "      <td>((AB, (1, 1)), (BB, (1, 2)), (AA, (1, 1)))</td>\n",
       "      <td>128</td>\n",
       "      <td>8.0000</td>\n",
       "      <td>[(AB, 0.02), (BB, 0.67), (AA, 0.31)]</td>\n",
       "      <td>[(BB, 0.67), (AA, 0.31)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>54001</td>\n",
       "      <td>((AB, (1, 3)), (AA, (2, 2)), (BB, (2, 1)), (AB...</td>\n",
       "      <td>98</td>\n",
       "      <td>6.1250</td>\n",
       "      <td>[(AB, 0.02), (AA, 0.352), (BB, 0.616), (AB, 0....</td>\n",
       "      <td>[(AA, 0.352), (BB, 0.616)]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     generation                                            min_jms  freq  \\\n",
       "43        54000  ((AB, (1, 3)), (BA, (2, 2)), (AA, (3, 3)), (BB...   476   \n",
       "14        54000  ((AB, (1, 3)), (AA, (2, 2)), (BB, (2, 1)), (AB...   160   \n",
       "183       54001  ((AB, (1, 3)), (BA, (2, 2)), (AA, (3, 3)), (BB...   375   \n",
       "167       54001         ((AB, (1, 1)), (BB, (1, 2)), (AA, (1, 1)))   128   \n",
       "173       54001  ((AB, (1, 3)), (AA, (2, 2)), (BB, (2, 1)), (AB...    98   \n",
       "\n",
       "     freq_perc                                            pdf_min  \\\n",
       "43     29.7500  [(AB, 0.02), (BA, 0.01), (AA, 0.326), (BB, 0.6...   \n",
       "14     10.0000  [(AB, 0.02), (AA, 0.316), (BB, 0.658), (AB, 0....   \n",
       "183    23.4375  [(AB, 0.02), (BA, 0.016), (AA, 0.338), (BB, 0....   \n",
       "167     8.0000               [(AB, 0.02), (BB, 0.67), (AA, 0.31)]   \n",
       "173     6.1250  [(AB, 0.02), (AA, 0.352), (BB, 0.616), (AB, 0....   \n",
       "\n",
       "                      pdf_cycle  \n",
       "43   [(AA, 0.326), (BB, 0.644)]  \n",
       "14   [(AA, 0.316), (BB, 0.658)]  \n",
       "183  [(AA, 0.338), (BB, 0.626)]  \n",
       "167    [(BB, 0.67), (AA, 0.31)]  \n",
       "173  [(AA, 0.352), (BB, 0.616)]  "
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#For visualization of joint machines with different frequency thresholds\n",
    "\n",
    "jm_freq_threshold = 5 #Change to higher for easier visualization (percentage)\n",
    "freqjm[freqjm.freq_perc > jm_freq_threshold] #keep machines with frequency higher than threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('AB', 0.02), ('BA', 0.01), ('AA', 0.326), ('BB', 0.644)]\n"
     ]
    }
   ],
   "source": [
    "print freqjm.pdf_min[43]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('AB', (1, 3)), ('BA', (2, 2)), ('AA', (3, 3)), ('BB', (3, 2)))"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqjm.min_jms[43]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>generation</th>\n",
       "      <th>av_score_row</th>\n",
       "      <th>av_score_col</th>\n",
       "      <th>miscoordination_perc</th>\n",
       "      <th>coordination_B_perc</th>\n",
       "      <th>coordination_A_perc</th>\n",
       "      <th>row_heads_A</th>\n",
       "      <th>row_heads_B</th>\n",
       "      <th>row_tails_A</th>\n",
       "      <th>row_tails_B</th>\n",
       "      <th>...</th>\n",
       "      <th>behaviour_slack_row</th>\n",
       "      <th>construction_slack_row</th>\n",
       "      <th>access_states_col</th>\n",
       "      <th>min_states_col</th>\n",
       "      <th>unused_states_col</th>\n",
       "      <th>unvisited_measure_col</th>\n",
       "      <th>behaviour_slack_col</th>\n",
       "      <th>construction_slack_col</th>\n",
       "      <th>regime_jm</th>\n",
       "      <th>regime_av</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54000</td>\n",
       "      <td>2.568600</td>\n",
       "      <td>2.219213</td>\n",
       "      <td>0.042438</td>\n",
       "      <td>0.653475</td>\n",
       "      <td>0.304088</td>\n",
       "      <td>284</td>\n",
       "      <td>39525</td>\n",
       "      <td>25098</td>\n",
       "      <td>15093</td>\n",
       "      <td>...</td>\n",
       "      <td>0.865625</td>\n",
       "      <td>0.865625</td>\n",
       "      <td>6.40</td>\n",
       "      <td>6.40</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.010714</td>\n",
       "      <td>0.80000</td>\n",
       "      <td>0.80000</td>\n",
       "      <td>not_threshold</td>\n",
       "      <td>Biased_Turn_B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54001</td>\n",
       "      <td>2.531887</td>\n",
       "      <td>2.211925</td>\n",
       "      <td>0.051237</td>\n",
       "      <td>0.634363</td>\n",
       "      <td>0.314400</td>\n",
       "      <td>530</td>\n",
       "      <td>39688</td>\n",
       "      <td>25864</td>\n",
       "      <td>13918</td>\n",
       "      <td>...</td>\n",
       "      <td>0.871875</td>\n",
       "      <td>0.871875</td>\n",
       "      <td>6.65</td>\n",
       "      <td>6.65</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.017857</td>\n",
       "      <td>0.83125</td>\n",
       "      <td>0.83125</td>\n",
       "      <td>not_threshold</td>\n",
       "      <td>Biased_Turn_B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   generation  av_score_row  av_score_col  miscoordination_perc  \\\n",
       "0       54000      2.568600      2.219213              0.042438   \n",
       "1       54001      2.531887      2.211925              0.051237   \n",
       "\n",
       "   coordination_B_perc  coordination_A_perc  row_heads_A  row_heads_B  \\\n",
       "0             0.653475             0.304088          284        39525   \n",
       "1             0.634363             0.314400          530        39688   \n",
       "\n",
       "   row_tails_A  row_tails_B      ...        behaviour_slack_row  \\\n",
       "0        25098        15093      ...                   0.865625   \n",
       "1        25864        13918      ...                   0.871875   \n",
       "\n",
       "   construction_slack_row  access_states_col  min_states_col  \\\n",
       "0                0.865625               6.40            6.40   \n",
       "1                0.871875               6.65            6.65   \n",
       "\n",
       "   unused_states_col  unvisited_measure_col  behaviour_slack_col  \\\n",
       "0              0.075               0.010714              0.80000   \n",
       "1              0.125               0.017857              0.83125   \n",
       "\n",
       "   construction_slack_col      regime_jm      regime_av  \n",
       "0                 0.80000  not_threshold  Biased_Turn_B  \n",
       "1                 0.83125  not_threshold  Biased_Turn_B  \n",
       "\n",
       "[2 rows x 38 columns]"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>duration</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [epoch, duration, start, end]\n",
       "Index: []"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs_av"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>duration</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>pdf</th>\n",
       "      <th>pdf_cycle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [epoch, duration, start, end, pdf, pdf_cycle]\n",
       "Index: []"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs_jm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1551    ((AB, (1, 2)), (AA, (2, 1)), (BB, (3, 3)), (AA...\n",
       "1778    ((AB, (1, 2)), (AA, (2, 1)), (BB, (3, 3)), (AA...\n",
       "1976    ((AB, (1, 2)), (AA, (2, 1)), (BB, (3, 3)), (AA...\n",
       "2087    ((AB, (1, 2)), (AA, (2, 1)), (BB, (3, 3)), (AA...\n",
       "Name: min_jms, dtype: object"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = freqjm[freqjm.freq_perc > jm_freq_threshold]\n",
    "jm_list = df.min_jms\n",
    "jm_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('AB', 0.001), ('AA', 0.000992), ('BB', 0.499338), ('AA', 0.49867)]\n"
     ]
    }
   ],
   "source": [
    "auto = jm_list[1551]\n",
    "pdf = minz.prob_density_function_joint_machine_with_signal(auto,1000,1000)#arguments are auto, tt, trials\n",
    "print pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
