{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Main file\n",
    "This main file is based on the scripts that I had for minimizing the machines from Netlogo. The original was made to capture output from Behaviour Space, processs the machines and then print it to use in Stata. This is too cumbersome, so decided to implement and do everything in Python so I can centralise all the analysis and work on the next algorithms such as Joint Machines, frequencies and unused behavioural states in order to analyse properly how the transitions are happening."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Run the first cell (to import libraries and load the minimization algorithms)\n",
    "2) In the next cell, decide the path where the netlogo output (in \"Table\" form) is. Comment everything in that cell except one file\n",
    "3) Run next cell (MAIN CODE)\n",
    "4) Decide path to save the file, and run final cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "\n",
    "# Big part of this code (canonical_automaton, remamp function and minimized_auto)is based on Warren's\n",
    "# version of Jhon Miller's code, originally in Java.\n",
    "\n",
    "# Create an empty auto as a numpy array\n",
    "def new_empty_auto():\n",
    "    dtype = [('actions', 'S1'), ('transitions', np.int32, n_obs)] # structure for \"normal_auto\" variable\n",
    "    new_auto = np.zeros(n_states, dtype) # initialize normal_auto (make all transitions zero)\n",
    "    new_auto['actions'] = 'x' # Make all actions x\n",
    "    return new_auto\n",
    "    \n",
    "    \n",
    "    \n",
    "# return a cannonically ordered auto stripped of inaccessible states\n",
    "def convert_to_canonical(normal_auto):\n",
    "    # statemap will keep track of which states are remapped, and the order in which they should be\n",
    "    # nextstate tracks the next available state number and eventually provides the number of accessible states\n",
    "    \n",
    "    statemap = np.ones(n_states)*(-1) #initialize map with null values\n",
    "    statemap[init_state] = 0 # initial state renumbered to state 0\n",
    "    nextstate = 1 # number of states remapped \n",
    "    # start it off with the start state, off to recursive remapper\n",
    "    nextstate = remap(init_state, normal_auto['transitions'], statemap, nextstate) # nextstate is the number of states remapped\n",
    "    \n",
    "    # Here, after the recursion of the 'remap' function, the two key variables obtained are nextstates and statemap\n",
    "    # nextstates was used to build statemap, but it contains the number of available states on the machine\n",
    "    # statemap shows which are those states, and in which order they are accessed.\n",
    "    \n",
    "    #print 'nextstate = ', nextstate\n",
    "    #print 'statemap (for canonical)= ', statemap\n",
    "    \n",
    "    auto = new_empty_auto() # Create new empty auto\n",
    "    for s in xrange(n_states):\n",
    "        if statemap[s] >= 0:   #if state is remapped (and accesible) \n",
    "            auto[statemap[s]]['actions'] = normal_auto[s]['actions']\n",
    "            for t in xrange(n_obs):\n",
    "                auto[statemap[s]]['transitions'][t] = statemap[normal_auto[s]['transitions'][t]] \n",
    "    auto = auto[:nextstate] # Cuts the auto to contain only the accesible states\n",
    "    \n",
    "    global updated_n_states # Used to \"get out\" of this function the local variable nexstate\n",
    "    updated_n_states = nextstate # To update n_states. Use this because nexstate is local variable\n",
    "    return auto\n",
    "\n",
    "\n",
    "# Function 'remap' is used to convert into canonical form ('convert_to_canonical')\n",
    "# ***recursively*** branches down automata and remaps everything via the ordered inputs\n",
    "def remap(state0, transitions, statemap, nextstate):\n",
    "    for t in xrange(n_obs): # for all possible observation/input\n",
    "        if statemap[transitions[state0][t]] < 0: # if that state is not yet remapped (i.e. is not -1)\n",
    "            statemap[transitions[state0][t]] = nextstate # assign it next available state num, then inc nstate (next line is the increase)\n",
    "            nextstate += 1\n",
    "            nextstate = remap(transitions[state0][t], transitions, statemap, nextstate) # recursively remap on this state\n",
    "    return nextstate  \n",
    "\n",
    "def minimized_automaton():\n",
    "    # define the equivalence matrix\n",
    "    equiv = np.zeros((n_states, n_states), dtype = bool)\n",
    "    for s1 in xrange(n_states): #All possible states pair combinations\n",
    "        for s2 in xrange(s1, n_states): \n",
    "            if canon_auto[s1]['actions'] == canon_auto[s2]['actions']: # Mark potentially equivalent states (i.e. with same action)\n",
    "                equiv[s1][s2] = True\n",
    "                equiv[s2][s1] = True # probably not needed, but cost is low\n",
    "    #print equiv\n",
    "    \n",
    "    # now refine the equivalence matrix by iterating transitions on transitions until it stablizes           \n",
    "    while True:\n",
    "        changed = False # Track if changes ocurred during the iteration. If no changes, we are done!\n",
    "        newequiv = np.zeros((n_states, n_states), dtype = bool) # Will contain the new equivalence matrix\n",
    "        for s1 in xrange(n_states): # All possible states pair combinations\n",
    "            for s2 in xrange(s1, n_states):\n",
    "                if equiv[s1][s2]: # for all potential equivalent states (i.e. states with same action)                  \n",
    "                    sametransitions = True # Assume they have the same transitions\n",
    "                    for t in xrange(n_obs): # for all transitions\n",
    "                        # Compares if the transitions in both states are the same (i.e. lead to the same action)\n",
    "                        if (not equiv[canon_auto[s1]['transitions'][t]][canon_auto[s2]['transitions'][t]]):\n",
    "                            sametransitions = False           \n",
    "                    newequiv[s1][s2] = sametransitions\n",
    "                    newequiv[s2][s1] = sametransitions\n",
    "                    if (not sametransitions): \n",
    "                        changed = True # At least one change was made, so iterate again\n",
    "        equiv = newequiv # Update the equivalence matrix to the modified one                         \n",
    "        if not changed: # if changed is False (no changes ocurred), then exit the loop\n",
    "            break\n",
    "\n",
    "    # equiv now holds the truly equivalent states, so remap these into a new, minimized automaton\n",
    "    # Make a new statemap to copy the new auto\n",
    "    statemap = np.array(xrange(n_states)) # initial statemap just maps to current state\n",
    "    for s1 in xrange(n_states):\n",
    "        for s2 in xrange(s1+1, n_states):\n",
    "            if equiv[s1][s2]:\n",
    "                statemap[s2] = statemap[s1]\n",
    "    #statemap[init_state] = 0 # I think not needed\n",
    "    #print 'statemap (for minimization) = ', statemap\n",
    "\n",
    "    # This looks like the same procedure used for copying the canonical auto (uses the new statemap)\n",
    "    newauto = copy.deepcopy(canon_auto)\n",
    "    #print 'newauto', newauto\n",
    "    for s in xrange(n_states):\n",
    "        newauto[statemap[s]]['actions'] = canon_auto[s]['actions']\n",
    "        for t in xrange(n_obs):\n",
    "            newauto[statemap[s]]['transitions'][t] = statemap[canon_auto[s]['transitions'][t]]\n",
    "    newauto = convert_to_canonical(newauto)\n",
    "    return newauto \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Choose file to work with. Comment all except the one to use\n",
    "\n",
    "# Import .csv file given by Netlogo. skiprows used to skip imkporting first rows, which are Netlogo info (not variable)\n",
    "\n",
    "# Path in my WINDOWS desktop\n",
    "data = pd.read_csv('C:/Users/lexlale/Dropbox/Thesis Phd/Coordination autos Chapter three/Netlogo original files/\\\n",
    "Autos-Coordination 8S 100,000 periods-table (3 of 3).csv', skiprows = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "############################################\n",
    "############################################\n",
    "############################################\n",
    "# MAIN code follows\n",
    "############################################\n",
    "############################################\n",
    "\n",
    "#Define new labels for the variables. Careful that the order of the reporters in the Netlogo file don't change,\n",
    "# otherwise the variables would be mixed up\n",
    "new_variable_labels = ['run_number',\n",
    "'n_states',\n",
    "'n-signal-cards',\n",
    "'game_played',\n",
    "'n_rounds',\n",
    "'n_populations',\n",
    "'n_outputs',\n",
    "'N',\n",
    "'n_signals',\n",
    "'N_parents',\n",
    "'generation',\n",
    "'av_score_row',\n",
    "'av_score_column',\n",
    "'av_score',\n",
    "'parent_col_0',\n",
    "'parent_col_1',\n",
    "'parent_col_2',\n",
    "'parent_col_3',\n",
    "'parent_col_4',\n",
    "'parent_col_5',\n",
    "'parent_col_6',\n",
    "'parent_col_7',\n",
    "'parent_col_8',\n",
    "'parent_col_9',\n",
    "'parent_col_10',\n",
    "'parent_col_11',\n",
    "'parent_col_12',\n",
    "'parent_col_13',\n",
    "'parent_col_14',\n",
    "'parent_col_15',\n",
    "'parent_col_16',\n",
    "'parent_col_17',\n",
    "'parent_col_18',\n",
    "'parent_col_19',\n",
    "'offspring_col_0',\n",
    "'offspring_col_1',\n",
    "'offspring_col_2',\n",
    "'offspring_col_3',\n",
    "'offspring_col_4',\n",
    "'offspring_col_5',\n",
    "'offspring_col_6',\n",
    "'offspring_col_7',\n",
    "'offspring_col_8',\n",
    "'offspring_col_9',\n",
    "'offspring_col_10',\n",
    "'offspring_col_11',\n",
    "'offspring_col_12',\n",
    "'offspring_col_13',\n",
    "'offspring_col_14',\n",
    "'offspring_col_15',\n",
    "'offspring_col_16',\n",
    "'offspring_col_17',\n",
    "'offspring_col_18',\n",
    "'offspring_col_19',\n",
    "'parent_row_0',\n",
    "'parent_row_1',\n",
    "'parent_row_2',\n",
    "'parent_row_3',\n",
    "'parent_row_4',\n",
    "'parent_row_5',\n",
    "'parent_row_6',\n",
    "'parent_row_7',\n",
    "'parent_row_8',\n",
    "'parent_row_9',\n",
    "'parent_row_10',\n",
    "'parent_row_11',\n",
    "'parent_row_12',\n",
    "'parent_row_13',\n",
    "'parent_row_14',\n",
    "'parent_row_15',\n",
    "'parent_row_16',\n",
    "'parent_row_17',\n",
    "'parent_row_18',\n",
    "'parent_row_19',\n",
    "'offspring_row_0',\n",
    "'offspring_row_1',\n",
    "'offspring_row_2',\n",
    "'offspring_row_3',\n",
    "'offspring_row_4',\n",
    "'offspring_row_5',\n",
    "'offspring_row_6',\n",
    "'offspring_row_7',\n",
    "'offspring_row_8',\n",
    "'offspring_row_9',\n",
    "'offspring_row_10',\n",
    "'offspring_row_11',\n",
    "'offspring_row_12',\n",
    "'offspring_row_13',\n",
    "'offspring_row_14',\n",
    "'offspring_row_15',\n",
    "'offspring_row_16',\n",
    "'offspring_row_17',\n",
    "'offspring_row_18',\n",
    "'offspring_row_19',\n",
    "'mutants_row',\n",
    "'mutants_column',\n",
    "'times_of_miscoordination',\n",
    "'times_of_row_preference',\n",
    "'times_of_column_preference']\n",
    "\n",
    "data.columns = new_variable_labels # Assign new labels as variable names (columns of the dataframe)\n",
    "\n",
    "# Make sure to include here all the columns with autos to minimize.\n",
    "\n",
    "cols = ['parent_col_0',\n",
    "'parent_col_1',\n",
    "'parent_col_2',\n",
    "'parent_col_3',\n",
    "'parent_col_4',\n",
    "'parent_col_5',\n",
    "'parent_col_6',\n",
    "'parent_col_7',\n",
    "'parent_col_8',\n",
    "'parent_col_9',\n",
    "'parent_col_10',\n",
    "'parent_col_11',\n",
    "'parent_col_12',\n",
    "'parent_col_13',\n",
    "'parent_col_14',\n",
    "'parent_col_15',\n",
    "'parent_col_16',\n",
    "'parent_col_17',\n",
    "'parent_col_18',\n",
    "'parent_col_19',\n",
    "'offspring_col_0',\n",
    "'offspring_col_1',\n",
    "'offspring_col_2',\n",
    "'offspring_col_3',\n",
    "'offspring_col_4',\n",
    "'offspring_col_5',\n",
    "'offspring_col_6',\n",
    "'offspring_col_7',\n",
    "'offspring_col_8',\n",
    "'offspring_col_9',\n",
    "'offspring_col_10',\n",
    "'offspring_col_11',\n",
    "'offspring_col_12',\n",
    "'offspring_col_13',\n",
    "'offspring_col_14',\n",
    "'offspring_col_15',\n",
    "'offspring_col_16',\n",
    "'offspring_col_17',\n",
    "'offspring_col_18',\n",
    "'offspring_col_19',\n",
    "'parent_row_0',\n",
    "'parent_row_1',\n",
    "'parent_row_2',\n",
    "'parent_row_3',\n",
    "'parent_row_4',\n",
    "'parent_row_5',\n",
    "'parent_row_6',\n",
    "'parent_row_7',\n",
    "'parent_row_8',\n",
    "'parent_row_9',\n",
    "'parent_row_10',\n",
    "'parent_row_11',\n",
    "'parent_row_12',\n",
    "'parent_row_13',\n",
    "'parent_row_14',\n",
    "'parent_row_15',\n",
    "'parent_row_16',\n",
    "'parent_row_17',\n",
    "'parent_row_18',\n",
    "'parent_row_19',\n",
    "'offspring_row_0',\n",
    "'offspring_row_1',\n",
    "'offspring_row_2',\n",
    "'offspring_row_3',\n",
    "'offspring_row_4',\n",
    "'offspring_row_5',\n",
    "'offspring_row_6',\n",
    "'offspring_row_7',\n",
    "'offspring_row_8',\n",
    "'offspring_row_9',\n",
    "'offspring_row_10',\n",
    "'offspring_row_11',\n",
    "'offspring_row_12',\n",
    "'offspring_row_13',\n",
    "'offspring_row_14',\n",
    "'offspring_row_15',\n",
    "'offspring_row_16',\n",
    "'offspring_row_17',\n",
    "'offspring_row_18',\n",
    "'offspring_row_19']\n",
    "\n",
    "# This basically drops the first two observations per run of the simulation (tick==0 and 1)\n",
    "data = data[data['generation'] != 0]  # Drop observations (rows) for which some autos are not reported\n",
    "data = data[data['generation'] != 1]\n",
    "\n",
    "# Uncomment next line to make it run on selected columns (for testing)\n",
    "#cols = ['parent_col_1', 'parent_row_1'] # To test and use only few columns\n",
    "#temporal_index = [10]\n",
    "\n",
    "#for each column containing autos (cols), and each round (data.index)\n",
    "for var in cols:\n",
    "    label = 'min_' + var\n",
    "    data[label] = np.nan # New column to insert minimized auto for each parent\n",
    "    for ix in data.index: # Change \"temporal_index\" for \"data.index\" for the full run (all rows)\n",
    "        big_auto = data[var][ix] #Choose one auto (Netlogo passes it, in my code, in Unicode format)\n",
    "        \n",
    "        # Next block is to clean the auto, because from Netlogo (Excel file) it comes formatted\n",
    "        big_auto = big_auto.encode(\"ascii\") # Convert to string\n",
    "        #print type(big_auto) # Should be string\n",
    "        big_auto = big_auto.replace('[','') # Delete useless characters\n",
    "        big_auto = big_auto.replace(']','')\n",
    "        big_auto = big_auto.replace('\"','')\n",
    "        big_auto = big_auto.split(' ') # Converts the string into a list\n",
    "        \n",
    "        for i in xrange(len(big_auto)): # This \"for\" converts all the numbers (transitions) into integers\n",
    "            if big_auto[i] != 'A' and big_auto[i] != 'B':\n",
    "                big_auto[i] = int(big_auto[i])\n",
    "        #print 'original auto = ', big_auto, type(big_auto)\n",
    "        \n",
    "        # Next block saves some variables of the auto (number of states, number of observations, etc.)\n",
    "        n_states = data['n_states'][ix] # Number of internal states of the auto\n",
    "        #print 'number of states = ', n_states\n",
    "        # The possible observations depend on the number of signals and the possible output of the machine\n",
    "        # If no signal, can only observe rival playing A or B. Otherwise (i.e. one signal), is A or B for each signal (Heads or Tails)\n",
    "        n_obs = 2 if data['n_signals'][ix] == 0 else 4\n",
    "        #print 'number of observations = ', n_obs\n",
    "        init_state = big_auto[0] # First item in the string represents the initial state\n",
    "        #print 'initial state = ', init_state\n",
    "        \n",
    "        normal_auto = new_empty_auto() # Create the auto as a numpy array.\n",
    "        \n",
    "        # Fill the new 'normal_auto' with the information from big_auto. So normal_auto=big_auto but as an array\n",
    "        my_index = xrange(1, len(big_auto), n_obs + 1) # Each number in the index is where a state starts\n",
    "        for i, j in enumerate(my_index):\n",
    "            normal_auto['actions'][i] = big_auto[j]\n",
    "            normal_auto['transitions'][i] = big_auto[j + 1:j + n_obs + 1]\n",
    "        #print 'auto as an array = ', normal_auto, type(normal_auto)\n",
    "        \n",
    "        # Convert to canonical form\n",
    "        canon_auto = convert_to_canonical(normal_auto) # returns normal_auto in canonical form, and assigns it to canon_auto\n",
    "        #print 'auto in canon form = ', canon_auto\n",
    "        \n",
    "        n_states = updated_n_states # n_states now is only the accesible states\n",
    "        init_state = 0 # After in canonical form , the initial state is always 0 (by definition)\n",
    "        #print 'n_states = ', n_states\n",
    "        \n",
    "        min_auto = minimized_automaton() # Now minimize the auto\n",
    "        #print 'min_auto = ', min_auto\n",
    "        \n",
    "        print_auto = np.array_str(min_auto) # The min_auto is passed as a string (not an array) for easy printing\n",
    "        \n",
    "        print_auto = print_auto.replace('[','') # Make the string less cluttered\n",
    "        print_auto = print_auto.replace(']','')\n",
    "        print_auto = print_auto.replace(\"'\",'')\n",
    "        print_auto = print_auto.replace(',',' ')\n",
    "        print_auto = print_auto.replace('\\n', '')\n",
    "        #print 'print_auto = ', print_auto\n",
    "        \n",
    "        data.loc[ix, label] = print_auto # Print the minimized auto as a string into the dataframe\n",
    "        \n",
    "sorted_df = data.sort(['run_number', 'generation']) #Sort the data\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Path and name of the file with the minimized autos to be saved\n",
    "\n",
    "#Path for WINDOWS desktop office\n",
    "sorted_df.to_excel('C:/Users/lexlale/Dropbox/Thesis Phd/Coordination autos Chapter three/\\\n",
    "8S 100,000 periods-table (3 of 3).xls')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
