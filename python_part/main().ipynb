{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Main file\n",
    "This main file is based on the scripts that I had for minimizing the machines from Netlogo. The original was made to capture output from Behaviour Space, processs the machines and then print it to use in Stata. This is too cumbersome, so decided to implement and do everything in Python so I can centralise all the analysis and work on the next algorithms such as Joint Machines, frequencies and unused behavioural states in order to analyse properly how the transitions are happening."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#1 Receiving the Netlogo output\n",
    "The first step is to load the files. Also, as the global variables of interest in order to associate it with the output name file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import random\n",
    "from __future__ import division\n",
    "from __future__ import with_statement\n",
    "import minimization as minz #My script in same folder for minimization routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Choose here the Globals and Name used for the experiment to load.\n",
    "#Make sure the files exist (i.e. from Netlogo simulations)\n",
    "experiment_clue = \"trial1\"\n",
    "n_states = 8\n",
    "n_signals = 1 #only without signal for now\n",
    "n_rounds = 20\n",
    "N = 40\n",
    "n_parents = 20\n",
    "\n",
    "#Choose generations to load (\"None\" to import the whole file)\n",
    "start_gen=None\n",
    "number_of_gens=1 #So final generation imported is start_gen+number_of_gens-1\n",
    "\n",
    "###################################################################################\n",
    "###################################################################################\n",
    "###################################################################################\n",
    "\n",
    "#Equivalent of generations in the strategies file\n",
    "total_pop=80 #total number of autos per generation\n",
    "start_row_strat=(start_gen*total_pop if start_gen!=None else None)\n",
    "number_rows_strat=(number_of_gens*total_pop if number_of_gens!=None else None)\n",
    "\n",
    "\n",
    "globals_list = (experiment_clue, n_states, n_signals, n_rounds, N, n_parents) #Save them as a list\n",
    "\n",
    "#Experiment name based on the chosen experiment_clue and globals\n",
    "chosen_experiment = \"%s_states_%s_signal_%s_rounds_%s_N_%s_parents_%s.txt\" % globals_list\n",
    "\n",
    "#Both files have to use the same \"chosen experiment\" (to make sure come from the same simulation in Netlogo)\n",
    "summary_file_name = \"summary_\" + chosen_experiment #Summary output\n",
    "strategies_file_name = \"strategies_\" + chosen_experiment #Strategies output\n",
    "\n",
    "#Path to Netlogo outputs\n",
    "netlogo_folder = \"/Users/luisalejandrolee/Dropbox/Thesis Phd/\\\n",
    "Coordination autos Chapter three/outputs_from_netlogo/\" #Netlogo outputs in this folder\n",
    "\n",
    "#Get the first line as header (for when importing only some generations instead of the whole file)\n",
    "with open(netlogo_folder+summary_file_name, 'r') as f:\n",
    "    line_s = f.readline()\n",
    "    line_s = line_s.split(',')\n",
    "    line_s[len(line_s)-1]=line_s[len(line_s)-1].replace('\\n','')#Delete last special carachter \"\\n\"\n",
    "#For the strategies file\n",
    "with open(netlogo_folder+strategies_file_name, 'r') as f:\n",
    "    line_st = f.readline()\n",
    "    line_st = line_st.split(',')\n",
    "    line_st[len(line_st)-1]=line_st[len(line_st)-1].replace('\\n','')\n",
    "    \n",
    "#Read files and save them as data\n",
    "df_sum = pd.read_csv(netlogo_folder + summary_file_name,\\\n",
    "                     skiprows=start_gen,nrows=number_of_gens)\n",
    "\n",
    "df_strat = pd.read_csv(netlogo_folder + strategies_file_name,\\\n",
    "                       skiprows=start_row_strat,nrows=number_rows_strat)\n",
    "#Replace header using first row of file (instead of from imported data)\n",
    "df_sum.columns=line_s\n",
    "df_strat.columns=line_st\n",
    "\n",
    "summary = df_sum.copy() #allows to go directly to epoch characterization by average (without joint machines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#2 Minimise the automata\n",
    "Use the functions to have a simple code here for minimising the auto and storing other relevant variables (as available states, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Other required globals\n",
    "n_obs = 2 if n_signals == 0 else 4 #Define here (or change) the possible observations of the machines\n",
    "\n",
    "canon_autos_list = [] #Create empty lists to store the processed autos below\n",
    "min_autos_list = []\n",
    "\n",
    "\n",
    "for i in df_strat.index: #For each row...\n",
    "    netlogo_auto = df_strat.auto_long[i] #... for all netlogo_auto\n",
    "    big_auto = minz.to_format_netlogo_auto(netlogo_auto) #Use function to convert the raw Netlogo auto in a list format\n",
    "    init_state = big_auto[0] #Save initial state of the machine\n",
    "    normal_auto = minz.new_empty_auto(n_obs, n_states) #Use function to create a new empty auto as a numpy array\n",
    "\n",
    "    # Next block it to fill the new 'normal_auto' with the information from big_auto.\n",
    "    # The objective is that normal_auto=big_auto but as an array (instead of a list)\n",
    "    my_index = xrange(1, len(big_auto), n_obs + 1) # Each number in the index is where a state starts\n",
    "    for i, j in enumerate(my_index):\n",
    "        normal_auto['actions'][i] = big_auto[j]\n",
    "        normal_auto['transitions'][i] = big_auto[j + 1:j + n_obs + 1]\n",
    "        \n",
    "    canon_auto = minz.convert_to_canonical(normal_auto, n_states, init_state, n_obs) #Use function for canonical form\n",
    "    \n",
    "    access_states = len(canon_auto) #n_states now is only the accesible states of the machine (before minimization)\n",
    "    \n",
    "    #Use function to get minimum behavioural equivalent auto\n",
    "    #Passes \"0\" as 3rd argument because that's init_state now (always 0 for canonical auto)\n",
    "    min_auto = minz.minimized_automaton(canon_auto, access_states, 0, n_obs)\n",
    "    \n",
    "    #Update autos lists\n",
    "    canon_autos_list.append(canon_auto) #Store proccessed autos in the corresponding list\n",
    "    min_autos_list.append(min_auto)\n",
    "    \n",
    "#Add the processed autos lists as columns to df_strat\n",
    "df_strat[\"canon_autos\"] = canon_autos_list #Add the lists with autos to the dataframe\n",
    "df_strat[\"min_autos\"] = min_autos_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#3 Accesible states and minimum behavioural states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "access_states = [len(x) for x in df_strat.canon_autos] #accesible states in the big machine\n",
    "min_states = [len(x) for x in df_strat.min_autos] #accesible states in the minimized machine\n",
    "\n",
    "df_strat[\"access_states\"] = access_states\n",
    "df_strat[\"min_states\"] = min_states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#4 Joint machines (not minimized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation =  0\n"
     ]
    }
   ],
   "source": [
    "# Lists to keep track of joint machines\n",
    "gen_list = []\n",
    "jm_list = []\n",
    "parents_index_list = []\n",
    "\n",
    "for gen in df_sum.generation: #each generation   \n",
    "    print \"generation = \", gen #Useful for debugging (or keeping track of simulation time)\n",
    "    df_col = df_strat[(df_strat.population == \"column\") & (df_strat.generation == gen)][:] #column autos for this gen\n",
    "    df_row = df_strat[(df_strat.population == \"row\") & (df_strat.generation == gen)][:] #row autos for this gen\n",
    "    \n",
    "    for i0, auto0 in enumerate(df_col.min_autos):#minimized autos in population col, for this gen\n",
    "        index_0=df_col.index[i0]\n",
    "        \n",
    "        for i1, auto1 in enumerate(df_row.min_autos):#minimized autos in population row, for this gen\n",
    "            index_1=df_row.index[i1]\n",
    "            \n",
    "            if n_signals==1: #With signal\n",
    "                jm = minz.create_joint_machine_with_signal(auto0, auto1) #Function to create the joint machine\n",
    "            if n_signals==0: #No signal\n",
    "                jm = minz.create_joint_machine_no_signal(auto0, auto1) #Function to create the joint machine\n",
    "            \n",
    "            gen_list.append(gen) #Keeps track of generation\n",
    "            jm_list.append(jm)   #Keeps track of joint machines\n",
    "            #Parents_index_list Keeps track of joint machine constituent machines' location (index) in df_strat\n",
    "            parents_index_list.append([index_0, index_1]) #Needed for Unused states measure\n",
    "            \n",
    "#Store the joint machines, generation and parent index (in a new dataframe)\n",
    "df_jms = pd.DataFrame(columns = (\"generation\", \"jm\", \"parents_index\")) #Store joint machines with associated generation\n",
    "df_jms.generation = gen_list\n",
    "df_jms.jm = jm_list\n",
    "df_jms.parents_index = parents_index_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#5 Minimize the joint machines \n",
    "Adds the 'min_jm' column to df_jms (tuples with the minimized joint machines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "min_jm_list = [] #to save the minimized joint machines, and add later to the dataframe (df_jms)\n",
    "\n",
    "for jm in df_jms.jm: #all joint machines\n",
    "#for jm in [df_jms.jm[24000], df_jms.jm[24001]]:\n",
    "\n",
    "    if n_signals==1:#with signal\n",
    "        canon_jm = minz.convert_to_canonical(jm, len(jm), 0, 2)\n",
    "        min_jm = minz.minimized_automaton(canon_jm, len(canon_jm), 0, 2)\n",
    "\n",
    "        #Next lines convert the min_jms, which is a dict, into a tuple\n",
    "        #Converts an structured numpy array (\"actions\" and 'transitions' in the min_jm)into a tuple of tuples\n",
    "        #This is so that it can be used as a key to use groupby (since tuple is inmutable)\n",
    "        tup_transitions = tuple(tuple(pair_transitions) for pair_transitions in min_jm[\"transitions\"])\n",
    "        tup_actions = tuple(min_jm['actions'])\n",
    "        min_jm = tuple(zip(tup_actions,tup_transitions))\n",
    "    \n",
    "    if n_signals==0:#no signal\n",
    "        min_jm = minz.minimize_joint_machine_no_signal(jm) #minimize them (have actions and cyclestart)\n",
    "        #Next lines convert the min_jms, which is a dict, into a tuple\n",
    "        #Converts a list of lists (\"actions\" in the min_jm)into a tuple of tuples\n",
    "        #This is so that it can be used as a key to use groupby (since tuple is inmutable)\n",
    "        tup_actions = tuple(tuple(pair_actions) for pair_actions in min_jm[\"actions\"]) #convert actions to tuples\n",
    "        min_jm = (tup_actions, min_jm[\"cyclestart\"]) #add the cyclestart to final min_jm tuple        \n",
    "    \n",
    "\n",
    "    min_jm_list.append(min_jm) #save the minimized machine to a list\n",
    "\n",
    "# Save the minimized joint machines\n",
    "df_jms[\"min_jms\"] = None #new empty column in dataframe\n",
    "df_jms.min_jms = min_jm_list #add the minimized joint machines to the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Probability Density Function for not minimized joint machines (with signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if n_signals == 0:\n",
    "    pass\n",
    "\n",
    "if n_signals == 1:\n",
    "    pdf_list = [] #to save the pdf of each joint machine and add later to the dataframe (df_jms)\n",
    "    \n",
    "    for jm in df_jms.jm:\n",
    "        #Here jm is the joint machine (not minimized), followed by the number of signals to feed the machine with,\n",
    "        #followed by the number of trials (repeats of feeding the signal). The total number of repetitions to obtain\n",
    "        #the PDF, is then tt*trials. Check the function in 'minimization'.\n",
    "        pdf = minz.prob_density_function_joint_machine_with_signal(jm,100,100)#arguments are auto, tt, trials\n",
    "        pdf_list.append(pdf)\n",
    "    \n",
    "    # Save the minimized joint machines\n",
    "    df_jms[\"pdf_long_jm\"] = None #new empty column in dataframe\n",
    "    df_jms.pdf_long_jm = pdf_list #add the minimized joint machines to the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Used states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Prepare dataframe to keep track of unused states\n",
    "df_strat[\"used_states\"] = 0 # Will contain a list with states of each min_auto\n",
    "used_states_list = []\n",
    "for i, auto in enumerate(df_strat.min_autos): #all minimized autos\n",
    "    a = [0 for ix in xrange(df_strat.min_states[i])] #List the size of minimised machine's states\n",
    "    used_states_list.append(a)\n",
    "df_strat[\"used_states\"] = used_states_list #Add to dataframe\n",
    "\n",
    "\n",
    "for i,jm in enumerate(df_jms.jm): #all joint machines (the not minimized ones)\n",
    "    index_0 = df_jms['parents_index'][i][0]#Index reference for parent machine (parents are in df_strat)\n",
    "    index_1 = df_jms['parents_index'][i][1]\n",
    "    \n",
    "    if n_signals==0: #No signal\n",
    "        for st in jm[\"states\"]: #for metastates in jointmachine\n",
    "            s0 = st[0] #state that is used by parent0 (stored in current metastate)\n",
    "            #Go to the parent machine (in df_strat) and alter the 'used_states' list\n",
    "            df_strat[\"used_states\"][index_0][s0] = 1# =1 for states visited. Unvisited remain 0\n",
    "\n",
    "        for st in jm[\"states\"]:\n",
    "            s1 = st[1]\n",
    "            df_strat[\"used_states\"][index_1][s1] = 1\n",
    "\n",
    "    #HERE could be a good place when decided on how to calculate used states with signal        \n",
    "    if n_signals==1: #with signal\n",
    "        #Create a list (only once, because is the same for all) with the states combinations (0,0),(0,1),..., which\n",
    "        #position 0 contains the used states in metastate 0 by both parents  \n",
    "        \n",
    "        #Get the pdf of the joint machine (is in df_jms)\n",
    "        #Get a list, based on the pdf, with the states that have zero probability (get position in pdf if item==0.0)\n",
    "        #for each item in the above, go to the first list (combinations) and get the used states for each parent\n",
    "        #mark those states for each parent in df_strat\n",
    "        \n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#6 Frequencies of minimized joint machines\n",
    "Outputs dataframe \"freqjm\" with frequencies of joint machines\n",
    "(Does it by transforming df_jms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Use Groupby and organize the data set for frequencies\n",
    "\n",
    "g1 = df_jms.copy() #use intermediate copies to avoid potential bugs later. Not sure if actually needed...\n",
    "g1 = g1.groupby([g1[\"generation\"], g1[\"min_jms\"]]) #split by groups\n",
    "g1 = g1.count() #organize as frequency of joint machine per generation\n",
    "\n",
    "interactions = N * N #number of joint machines per generation\n",
    "freq_perc_list = [(x*100)/interactions for x in g1.jm] #list with frequency percentage of jm per generation\n",
    "g1['freq_perc'] = freq_perc_list #add frequency to the dataframe\n",
    "\n",
    "#jm_freq_threshold = 0 #Change to higher for easier visualization\n",
    "#g1 = g1[g1.freq_perc > jm_freq_threshold] #keep machines with frequency higher than threshold\n",
    "\n",
    "\n",
    "#Organise the dataframe\n",
    "\n",
    "freqjm = g1.copy() #just in case...\n",
    "freqjm = freqjm.rename(columns = {'jm':'freq'}) #rename column\n",
    "freqjm = freqjm.reset_index() #reset_index converts the multiindex into normal columns (to use generation for 'sort')\n",
    "freqjm = freqjm.sort(['generation', 'freq_perc'], ascending=[True, False]) #sort\n",
    "\n",
    "\n",
    "#If no signal, show the lollipop machine as a string. Example: \"AA BB >>AA<<\"\" for a machines that plays first\n",
    "#AA, then BB, and then forever plays AA (whatever is inside >> << is the metamachine cycle)\n",
    "if n_signals==0:#no signal\n",
    "    jm_show = [minz.min_jm_no_signal_to_string(x) for x in freqjm.min_jms] #use function to convert to string\n",
    "    freqjm['jm_show'] = jm_show #add to dataframe\n",
    "\n",
    "#With signal, perhaps the jm_show (a good way to show the joint machine), is by using the Markov matrix\n",
    "if n_signals==1:#no signal\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#7 Unused behaviour and slack in construction measures\n",
    "\n",
    "Unused not ready for signal. Check later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if n_signals==0:#for now, only without signal\n",
    "    #Unused states: number of states not visited in the minimized machine\n",
    "    unused_states = [len(x) - x.count(1) for x in df_strat.used_states] #unused states in min_autos\n",
    "    \n",
    "    #Unvisited: potential for novel behavior given change in the  input stream. Is unused states divided by min_states\n",
    "    unvisited_measure = [(len(x)-x.count(1))/len(x) for x in df_strat.used_states]\n",
    "\n",
    "#Behaviour_slack: slack in the potential behavior of the machine\n",
    "#the more states you use, the more sophisticated you can become behaviorally.\n",
    "behaviour_slack = [len(x)/n_states for x in df_strat.min_autos] #min_lenght/total states.\n",
    "\n",
    "#construction_slack: slack in the construction of the complete machine\n",
    "construction_slack = [x/n_states for x in df_strat.access_states]#accesible/total\n",
    "\n",
    "if n_signals==0:#for now, only without signal:\n",
    "    df_strat['unused_states'] = unused_states\n",
    "    df_strat['unvisited_measure'] = unvisited_measure\n",
    "    \n",
    "df_strat['behaviour_slack'] = behaviour_slack\n",
    "df_strat['construction_slack'] = construction_slack\n",
    "\n",
    "#df_strat = df_strat.drop('used_states', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Take the average per generation of unused states, unvisited measure, and slack measures\n",
    "\n",
    "strats = df_strat.copy() #just in case\n",
    "strats = strats.groupby(strats.generation).mean() #take the mean of all the variables (by generation)\n",
    "strats = strats.drop(['ID','score',],1) #not needed (1 is to drop columns instead of rows)\n",
    "strats = strats.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Organise summary dataframe, and include the measures calculated above.\n",
    "\n",
    "summary = df_sum.copy() #just in case\n",
    "#delete columns that won't use\n",
    "#to_delete = ['row_heads_A', 'row_heads_B', 'row_tails_A', 'row_tails_B', 'col_heads_A', 'col_heads_B',\\\n",
    "#'col_tails_A','col_tails_B','times_heads','times_tails']\n",
    "#summary = summary.drop(to_delete, axis=1)\n",
    "\n",
    "summary = pd.merge(summary, strats, on='generation') #merge datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#8 Regime identification\n",
    "Two regime classifications: based on top joint machine and based on percentage of play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#By top joint machine:\n",
    "#Function to find the highest frequency percentage top machine\n",
    "def find_top_jm (df, n=1, column='freq_perc'):\n",
    "    return df.sort_index(by=column)[-n:]\n",
    "\n",
    "#Apply the function to get the highest frequency joint machine per generation\n",
    "topjm = freqjm.groupby('generation').apply(find_top_jm)\n",
    "\n",
    "#Define regime as the top joint machine in a generation if its frequency is above the defined \"regime_threshold\"\n",
    "#percentage. If none is above it, the regime is in \"other\"\n",
    "regime_threshold = 50 \n",
    "regime_jm = [jm if int(topjm.freq_perc[i]) > regime_threshold else 'not_threshold' for i,jm in enumerate(topjm.min_jms)]\n",
    "\n",
    "#Add regime to summary dataframe\n",
    "summary['regime_jm'] = regime_jm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#By percentage:\n",
    "regime_av = [None for i in summary.index] #Create variable to fill\n",
    "\n",
    "#Regime based on percetanges of machines playing AA or BB\n",
    "for i in summary.index: #all generations\n",
    "    \n",
    "    A = summary.coordination_A_perc[i] #percentage of AA plays for this generation\n",
    "    B = summary.coordination_B_perc[i] #percentage of BB plays for this generation\n",
    "    \n",
    "    if A > 0.8:\n",
    "        regime_av[i] = 'Domination_AA'\n",
    "    elif B > 0.8:\n",
    "        regime_av[i] = 'Domination_BB'\n",
    "    elif A > 0.35 and A < 0.55 and B > 0.35 and B < 0.55:\n",
    "        regime_av[i] = 'Turn_Taking'\n",
    "    elif A > 0.5 and A < 0.8 and B > 0.2 and B < 0.5:\n",
    "        regime_av[i] = 'Biased_Turn_A'\n",
    "    elif B > 0.5 and B < 0.8 and A > 0.2 and A < 0.5:\n",
    "        regime_av[i] = 'Biased_Turn_B'\n",
    "    else:\n",
    "        regime_av[i] = 'Other'\n",
    "        \n",
    "summary['regime_av'] = regime_av  \n",
    "#summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#9 Epoch characterization\n",
    "Two Epoch matrices are constructed: \"epoch_av\", with epochs based on the average percentage of AA and BB per generation (computationally much faster and doesn't require previous procedures but only the summary matrix), and \"epoch_jm\" which is based on the top machine of the generation\n",
    "\n",
    "An epoch is defined as having the top joint machine on a generation (i.e. regime) to be the same over a window of \n",
    "past generations (e.g. was this period the same regime as in the past ones?). In that window of past regimes, some tolerance is permitted (i.e. some of them can be different, allowing for some errors).\n",
    "\n",
    "The algorithm considers an epoch to have started when a regime appears a minimum number of times in the window of past regimes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Epoch characterization works well with 10 and 5 for long simulations\n",
    "epoch_window = 1 #lagged regimes to be considered\n",
    "epoch_tolerance = 0 #number of misses in the window before breaking an epoch\n",
    "\n",
    "#Use custom function to generate epoch matrix\n",
    "epochs_av=minz.epoch_matrix(summary,'regime_av',epoch_window,epoch_tolerance) #based on average percentages of (AA,BB)\n",
    "#print epochs_av"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Requires Joint Machines\n",
    "\n",
    "epochs_jm=minz.epoch_matrix(summary,'regime_jm',epoch_window,epoch_tolerance) #based on top joint machine\n",
    "#print epochs_jm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#10 Export main dataframes\n",
    "Export the three main data frames, so I can work with graphs and statistics from a different file. This makes the scripts a bit more modular, and also I just have to run the minimization procedures (this file) only once per experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_file_modifier='testing_' #To change the name of output file\n",
    "\n",
    "#Path to python outputs\n",
    "python_folder = \"/Users/luisalejandrolee/Dropbox/Thesis Phd/\\\n",
    "Coordination autos Chapter three/outputs_from_python/\" #Netlogo outputs in this folder\n",
    "\n",
    "#summary: contains main variables. Averages per generation\n",
    "summary.to_csv(python_folder+output_file_modifier+'summary_'+chosen_experiment)\n",
    "\n",
    "#freqjm: frequency of each joint machine per generation.\n",
    "freqjm.to_csv(python_folder+output_file_modifier+'jm_'+chosen_experiment)\n",
    "\n",
    "#epochs: each row has the regime \n",
    "#Top joint machine (if above threshold, otherwise \"not_threshold\")\n",
    "epochs_jm.to_csv((python_folder+output_file_modifier+'epochs_jm_'+chosen_experiment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Based on percentage of plays (AA and BB)\n",
    "epochs_av.to_csv((python_folder+output_file_modifier+'epochs_av_'+chosen_experiment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#STOP! no need to run the script further\n",
    "###Just for visualization\n",
    "freqjm: frequency of all joint machines per generation (for transition analysis)\n",
    "\n",
    "summary: main variables (averages per generation)\n",
    "\n",
    "epochs: classification of epochs, with duration, starting and ending periods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>generation</th>\n",
       "      <th>min_jms</th>\n",
       "      <th>freq</th>\n",
       "      <th>parents_index</th>\n",
       "      <th>freq_perc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [generation, min_jms, freq, parents_index, freq_perc]\n",
       "Index: []"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#For visualization of joint machines with different frequency thresholds\n",
    "\n",
    "jm_freq_threshold = 5 #Change to higher for easier visualization (percentage)\n",
    "freqjm[freqjm.freq_perc > jm_freq_threshold] #keep machines with frequency higher than threshold\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>generation</th>\n",
       "      <th>av_score_row</th>\n",
       "      <th>av_score_col</th>\n",
       "      <th>miscoordination_perc</th>\n",
       "      <th>coordination_B_perc</th>\n",
       "      <th>coordination_A_perc</th>\n",
       "      <th>row_heads_A</th>\n",
       "      <th>row_heads_B</th>\n",
       "      <th>row_tails_A</th>\n",
       "      <th>row_tails_B</th>\n",
       "      <th>...</th>\n",
       "      <th>times_heads</th>\n",
       "      <th>times_tails</th>\n",
       "      <th>ce</th>\n",
       "      <th>ce_individual</th>\n",
       "      <th>access_states</th>\n",
       "      <th>min_states</th>\n",
       "      <th>behaviour_slack</th>\n",
       "      <th>construction_slack</th>\n",
       "      <th>regime_jm</th>\n",
       "      <th>regime_av</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.2875</td>\n",
       "      <td>1.264844</td>\n",
       "      <td>0.489531</td>\n",
       "      <td>0.266562</td>\n",
       "      <td>0.243906</td>\n",
       "      <td>7974</td>\n",
       "      <td>8028</td>\n",
       "      <td>8033</td>\n",
       "      <td>7925</td>\n",
       "      <td>...</td>\n",
       "      <td>16002</td>\n",
       "      <td>15958</td>\n",
       "      <td>0.124715</td>\n",
       "      <td>0.444004</td>\n",
       "      <td>7.8375</td>\n",
       "      <td>7.825</td>\n",
       "      <td>0.978125</td>\n",
       "      <td>0.979688</td>\n",
       "      <td>not_threshold</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   generation  av_score_row  av_score_col  miscoordination_perc  \\\n",
       "0           0        1.2875      1.264844              0.489531   \n",
       "\n",
       "   coordination_B_perc  coordination_A_perc  row_heads_A  row_heads_B  \\\n",
       "0             0.266562             0.243906         7974         8028   \n",
       "\n",
       "   row_tails_A  row_tails_B    ...      times_heads  times_tails        ce  \\\n",
       "0         8033         7925    ...            16002        15958  0.124715   \n",
       "\n",
       "    ce_individual  access_states  min_states  behaviour_slack  \\\n",
       "0        0.444004         7.8375       7.825         0.978125   \n",
       "\n",
       "   construction_slack      regime_jm  regime_av  \n",
       "0            0.979688  not_threshold      Other  \n",
       "\n",
       "[1 rows x 24 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>duration</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [epoch, duration, start, end]\n",
       "Index: []"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs_av"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>duration</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [epoch, duration, start, end]\n",
       "Index: []"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs_jm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
