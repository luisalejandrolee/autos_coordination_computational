{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Main file\n",
    "This main file is based on the scripts that I had for minimizing the machines from Netlogo. The original was made to capture output from Behaviour Space, processs the machines and then print it to use in Stata. This is too cumbersome, so decided to implement and do everything in Python so I can centralise all the analysis and work on the next algorithms such as Joint Machines, frequencies and unused behavioural states in order to analyse properly how the transitions are happening."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#1 Receiving the Netlogo output\n",
    "The first step is to load the files. Also, as the global variables of interest in order to associate it with the output name file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "from __future__ import division\n",
    "from __future__ import with_statement\n",
    "import minimization as minz #My script in same folder for minimization routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Choose here the Globals and Name used for the experiment to load.\n",
    "#Make sure the files exist (i.e. from Netlogo simulations)\n",
    "experiment_clue = \"trial1\"\n",
    "n_states = 8\n",
    "n_signals = 1 #only without signal for now\n",
    "n_rounds = 20\n",
    "N = 40\n",
    "n_parents = 20\n",
    "\n",
    "#Choose generations to load (\"None\" to import the whole file)\n",
    "start_gen=None\n",
    "number_of_gens=5 #So final generation imported is start_gen+number_of_gens-1\n",
    "\n",
    "###################################################################################\n",
    "###################################################################################\n",
    "###################################################################################\n",
    "\n",
    "#Equivalent of generations in the strategies file\n",
    "total_pop=80 #total number of autos per generation\n",
    "start_row_strat=(start_gen*total_pop if start_gen!=None else None)\n",
    "number_rows_strat=(number_of_gens*total_pop if number_of_gens!=None else None)\n",
    "\n",
    "\n",
    "globals_list = (experiment_clue, n_states, n_signals, n_rounds, N, n_parents) #Save them as a list\n",
    "\n",
    "#Experiment name based on the chosen experiment_clue and globals\n",
    "chosen_experiment = \"%s_states_%s_signal_%s_rounds_%s_N_%s_parents_%s.txt\" % globals_list\n",
    "\n",
    "#Both files have to use the same \"chosen experiment\" (to make sure come from the same simulation in Netlogo)\n",
    "summary_file_name = \"summary_\" + chosen_experiment #Summary output\n",
    "strategies_file_name = \"strategies_\" + chosen_experiment #Strategies output\n",
    "\n",
    "#Path to Netlogo outputs\n",
    "netlogo_folder = \"/Users/luisalejandrolee/Dropbox/Thesis Phd/\\\n",
    "Coordination autos Chapter three/outputs_from_netlogo/\" #Netlogo outputs in this folder\n",
    "\n",
    "#Get the first line as header (for when importing only some generations instead of the whole file)\n",
    "with open(netlogo_folder+summary_file_name, 'r') as f:\n",
    "    line_s = f.readline()\n",
    "    line_s = line_s.split(',')\n",
    "    line_s[len(line_s)-1]=line_s[len(line_s)-1].replace('\\n','')#Delete last special carachter \"\\n\"\n",
    "#For the strategies file\n",
    "with open(netlogo_folder+strategies_file_name, 'r') as f:\n",
    "    line_st = f.readline()\n",
    "    line_st = line_st.split(',')\n",
    "    line_st[len(line_st)-1]=line_st[len(line_st)-1].replace('\\n','')\n",
    "    \n",
    "#Read files and save them as data\n",
    "df_sum = pd.read_csv(netlogo_folder + summary_file_name,\\\n",
    "                     skiprows=start_gen,nrows=number_of_gens)\n",
    "\n",
    "df_strat = pd.read_csv(netlogo_folder + strategies_file_name,\\\n",
    "                       skiprows=start_row_strat,nrows=number_rows_strat)\n",
    "#Replace header using first row of file (instead of from imported data)\n",
    "df_sum.columns=line_s\n",
    "df_strat.columns=line_st"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#2 Minimise the automata\n",
    "Use the functions to have a simple code here for minimising the auto and storing other relevant variables (as available states, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Other required globals\n",
    "n_obs = 2 if n_signals == 0 else 4 #Define here (or change) the possible observations of the machines\n",
    "\n",
    "canon_autos_list = [] #Create empty lists to store the processed autos below\n",
    "min_autos_list = []\n",
    "\n",
    "\n",
    "for i in df_strat.index: #For each row...\n",
    "    netlogo_auto = df_strat.auto_long[i] #... for all netlogo_auto\n",
    "    big_auto = minz.to_format_netlogo_auto(netlogo_auto) #Use function to convert the raw Netlogo auto in a list format\n",
    "    init_state = big_auto[0] #Save initial state of the machine\n",
    "    normal_auto = minz.new_empty_auto(n_obs, n_states) #Use function to create a new empty auto as a numpy array\n",
    "\n",
    "    # Next block it to fill the new 'normal_auto' with the information from big_auto.\n",
    "    # The objective is that normal_auto=big_auto but as an array (instead of a list)\n",
    "    my_index = xrange(1, len(big_auto), n_obs + 1) # Each number in the index is where a state starts\n",
    "    for i, j in enumerate(my_index):\n",
    "        normal_auto['actions'][i] = big_auto[j]\n",
    "        normal_auto['transitions'][i] = big_auto[j + 1:j + n_obs + 1]\n",
    "        \n",
    "    canon_auto = minz.convert_to_canonical(normal_auto, n_states, init_state, n_obs) #Use function for canonical form\n",
    "    \n",
    "    access_states = len(canon_auto) #n_states now is only the accesible states of the machine (before minimization)\n",
    "    \n",
    "    #Use function to get minimum behavioural equivalent auto\n",
    "    #Passes \"0\" as 3rd argument because that's init_state now (always 0 for canonical auto)\n",
    "    min_auto = minz.minimized_automaton(canon_auto, access_states, 0, n_obs)\n",
    "    \n",
    "    #Update autos lists\n",
    "    canon_autos_list.append(canon_auto) #Store proccessed autos in the corresponding list\n",
    "    min_autos_list.append(min_auto)\n",
    "    \n",
    "#Add the processed autos lists as columns to df_strat\n",
    "df_strat[\"canon_autos\"] = canon_autos_list #Add the lists with autos to the dataframe\n",
    "df_strat[\"min_autos\"] = min_autos_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#3 Accesible states and minimum behavioural states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "access_states = [len(x) for x in df_strat.canon_autos] #accesible states in the big machine\n",
    "min_states = [len(x) for x in df_strat.min_autos] #accesible states in the minimized machine\n",
    "\n",
    "df_strat[\"access_states\"] = access_states\n",
    "df_strat[\"min_states\"] = min_states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#4 Joint machine (not minimized)\n",
    "##Here for unused states when decided how to do it\n",
    "\n",
    "Outputs the df_jms including the NOT minimized joint machines.\n",
    "\n",
    "Outputs on df_strat the 'used_states' variable (containing list of used and unused states of minimized individual \n",
    "machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Prepare dataframe to keep track of unused states\n",
    "df_strat[\"used_states\"] = 0 # Will contain a list with states of each min_auto\n",
    "used_states_list = []\n",
    "for i, auto in enumerate(df_strat.min_autos): #all minimized autos\n",
    "    a = [0 for ix in xrange(df_strat.min_states[i])] #List the size of minimised machine's states\n",
    "    used_states_list.append(a)\n",
    "df_strat[\"used_states\"] = used_states_list #Add to dataframe\n",
    "\n",
    "# Lists to keep track of joint machines\n",
    "gen_list = []\n",
    "jm_list = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation =  0\n",
      "generation =  1\n",
      "generation =  2\n",
      "generation =  3\n",
      "generation = "
     ]
    }
   ],
   "source": [
    "#Create the joint machines (not minimized)\n",
    "\n",
    "\n",
    "for gen in df_sum.generation: #each generation\n",
    "    #======HERE FOR PRINTING TIME============ \n",
    "    print \"generation = \", gen #Useful for debugging (or keeping track of simulation time)\n",
    "    #Next lines (the \"for\" block) is tricky:\n",
    "    #It creates a dataframe containing only the autos with population = column and current generation.\n",
    "    #Uses \"iterrows()\" to iterate over the index of the dataframe (df_strat), keeping it on i0, which is\n",
    "    #needed to acces later the particular auto that was used for the joint machine (accesed by row0.min_autos)\n",
    "    #This is used (instead of a simple enumerate) to access that row later when updating the used states (no signal)\n",
    "    #Same logic for the second \"for\" block, but for population row.\n",
    "    \n",
    "    df_col = df_strat[(df_strat.population == \"column\") & (df_strat.generation == gen)][:] #column autos for this gen\n",
    "    df_row = df_strat[(df_strat.population == \"row\") & (df_strat.generation == gen)][:] #row autos for this gen\n",
    "    \n",
    "    for i0, row0 in df_col.iterrows():\n",
    "        for i1, row1 in df_row.iterrows():\n",
    "            \n",
    "            #print \"generation = \", gen, \"i0 = \", i0, \"i1 = \", i1\n",
    "            auto0 = row0.min_autos #Autos to pass to create_joint_machine function\n",
    "            auto1 = row1.min_autos\n",
    "            \n",
    "            if n_signals==1: #With signal\n",
    "                jm = minz.create_joint_machine_with_signal(auto0, auto1) #Function to create the joint machine\n",
    "            if n_signals==0: #No signal\n",
    "                jm = minz.create_joint_machine_no_signal(auto0, auto1) #Function to create the joint machine\n",
    "            \n",
    "            gen_list.append(gen) #Keeps track of generation\n",
    "            jm_list.append(jm)   #Keeps track of joint machines\n",
    "            \n",
    "            #Update used_states (NO SIGNAL YET):\n",
    "            #This part takes the information from the just create joint machine jm, which contains the states that\n",
    "            #are visited by the two autos that created it. For each auto, then goes trough each state. The\n",
    "            #list \"used_states\" contains a list of zeros with the number of states of the auto, each position\n",
    "            #representing each state of the auto. So if state 1 of the machine is used in the joint machine, then\n",
    "            #position 1 will be changed from zero to one, to indicate that the state is used.\n",
    "\n",
    "            if n_signals==0: #No signal\n",
    "                for st in jm[\"states\"]: #for metastates in jointmachine\n",
    "                    s0 = st[0] #state of auto0\n",
    "                    df_strat[\"used_states\"][i0][s0] = 1 # =1 for states visited. Unvisited remain 0\n",
    "\n",
    "                for st in jm[\"states\"]:\n",
    "                    s1 = st[1] #state of auto1\n",
    "                    df_strat[\"used_states\"][i1][s1] = 1\n",
    "                    \n",
    "            #HERE could be a good place when decided on how to calculate used states with signal        \n",
    "            if n_signals==1: #with signal\n",
    "                pass\n",
    "\n",
    "#Store the joint machines and generation (a new dataframe)\n",
    "df_jms = pd.DataFrame(columns = (\"generation\", \"jm\")) #Store joint machines with associated generation\n",
    "df_jms.generation = gen_list\n",
    "df_jms.jm = jm_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#5 Minimize the joint machines \n",
    "Adds the 'min_jm' column to df_jms (tuples with the minimized joint machines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "min_jm_list = [] #to save the minimized joint machines, and add later to the dataframe (df_jms)\n",
    "\n",
    "for jm in df_jms.jm: #all joint machines\n",
    "#for jm in [df_jms.jm[24000], df_jms.jm[24001]]:\n",
    "\n",
    "    if n_signals==1:#with signal\n",
    "        canon_jm = minz.convert_to_canonical(jm, len(jm), 0, 2)\n",
    "        min_jm = minz.minimized_automaton(canon_jm, len(canon_jm), 0, 2)\n",
    "\n",
    "        #Next lines convert the min_jms, which is a dict, into a tuple\n",
    "        #Converts an structured numpy array (\"actions\" and 'transitions' in the min_jm)into a tuple of tuples\n",
    "        #This is so that it can be used as a key to use groupby (since tuple is inmutable)\n",
    "        tup_transitions = tuple(tuple(pair_transitions) for pair_transitions in min_jm[\"transitions\"])\n",
    "        tup_actions = tuple(min_jm['actions'])\n",
    "        min_jm = tuple(zip(tup_actions,tup_transitions))\n",
    "    \n",
    "    if n_signals==0:#no signal\n",
    "        min_jm = minz.minimize_joint_machine_no_signal(jm) #minimize them (have actions and cyclestart)\n",
    "        #Next lines convert the min_jms, which is a dict, into a tuple\n",
    "        #Converts a list of lists (\"actions\" in the min_jm)into a tuple of tuples\n",
    "        #This is so that it can be used as a key to use groupby (since tuple is inmutable)\n",
    "        tup_actions = tuple(tuple(pair_actions) for pair_actions in min_jm[\"actions\"]) #convert actions to tuples\n",
    "        min_jm = (tup_actions, min_jm[\"cyclestart\"]) #add the cyclestart to final min_jm tuple        \n",
    "    \n",
    "\n",
    "    min_jm_list.append(min_jm) #save the minimized machine to a list\n",
    "\n",
    "# Save the minimized joint machines\n",
    "df_jms[\"min_jms\"] = None #new empty column in dataframe\n",
    "df_jms.min_jms = min_jm_list #add the minimized joint machines to the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#6 Frequencies of minimized joint machines\n",
    "Outputs dataframe \"freqjm\" with frequencies of joint machines\n",
    "(Does it by transforming df_jms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Use Groupby and organize the data set for frequencies\n",
    "\n",
    "g1 = df_jms.copy() #use intermediate copies to avoid potential bugs later. Not sure if actually needed...\n",
    "g1 = g1.groupby([g1[\"generation\"], g1[\"min_jms\"]]) #split by groups\n",
    "g1 = g1.count() #organize as frequency of joint machine per generation\n",
    "\n",
    "interactions = N * N #number of joint machines per generation\n",
    "freq_perc_list = [(x*100)/interactions for x in g1.jm] #list with frequency percentage of jm per generation\n",
    "g1['freq_perc'] = freq_perc_list #add frequency to the dataframe\n",
    "\n",
    "#jm_freq_threshold = 0 #Change to higher for easier visualization\n",
    "#g1 = g1[g1.freq_perc > jm_freq_threshold] #keep machines with frequency higher than threshold\n",
    "\n",
    "\n",
    "#Organise the dataframe\n",
    "\n",
    "freqjm = g1.copy() #just in case...\n",
    "freqjm = freqjm.rename(columns = {'jm':'freq'}) #rename column\n",
    "freqjm = freqjm.reset_index() #reset_index converts the multiindex into normal columns (to use generation for 'sort')\n",
    "freqjm = freqjm.sort(['generation', 'freq_perc'], ascending=[True, False]) #sort\n",
    "\n",
    "\n",
    "#If no signal, show the lollipop machine as a string. Example: \"AA BB >>AA<<\"\" for a machines that plays first\n",
    "#AA, then BB, and then forever plays AA (whatever is inside >> << is the metamachine cycle)\n",
    "if n_signals==0:#no signal\n",
    "    jm_show = [minz.min_jm_no_signal_to_string(x) for x in freqjm.min_jms] #use function to convert to string\n",
    "    freqjm['jm_show'] = jm_show #add to dataframe\n",
    "\n",
    "#With signal, perhaps the jm_show (a good way to show the joint machine), is by using the Markov matrix\n",
    "if n_signals==1:#no signal\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#7 Unused behaviour and slack in construction measures\n",
    "\n",
    "Unused not ready for signal. Check later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if n_signals==0:#for now, only without signal\n",
    "    #Unused states: number of states not visited in the minimized machine\n",
    "    unused_states = [len(x) - x.count(1) for x in df_strat.used_states] #unused states in min_autos\n",
    "    \n",
    "    #Unvisited: potential for novel behavior given change in the  input stream. Is unused states divided by min_states\n",
    "    unvisited_measure = [(len(x)-x.count(1))/len(x) for x in df_strat.used_states]\n",
    "\n",
    "#Behaviour_slack: slack in the potential behavior of the machine\n",
    "#the more states you use, the more sophisticated you can become behaviorally.\n",
    "behaviour_slack = [len(x)/n_states for x in df_strat.min_autos] #min_lenght/total states.\n",
    "\n",
    "#construction_slack: slack in the construction of the complete machine\n",
    "construction_slack = [x/n_states for x in df_strat.access_states]#accesible/total\n",
    "\n",
    "if n_signals==0:#for now, only without signal:\n",
    "    df_strat['unused_states'] = unused_states\n",
    "    df_strat['unvisited_measure'] = unvisited_measure\n",
    "    \n",
    "df_strat['behaviour_slack'] = behaviour_slack\n",
    "df_strat['construction_slack'] = construction_slack\n",
    "\n",
    "#df_strat = df_strat.drop('used_states', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Take the average per generation of unused states, unvisited measure, and slack measures\n",
    "\n",
    "strats = df_strat.copy() #just in case\n",
    "strats = strats.groupby(strats.generation).mean() #take the mean of all the variables (by generation)\n",
    "strats = strats.drop(['ID','score',],1) #not needed (1 is to drop columns instead of rows)\n",
    "strats = strats.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Organise summary dataframe, and include the measures calculated above.\n",
    "\n",
    "summary = df_sum.copy() #just in case\n",
    "#delete columns that won't use\n",
    "#to_delete = ['row_heads_A', 'row_heads_B', 'row_tails_A', 'row_tails_B', 'col_heads_A', 'col_heads_B',\\\n",
    "#'col_tails_A','col_tails_B','times_heads','times_tails']\n",
    "#summary = summary.drop(to_delete, axis=1)\n",
    "\n",
    "summary = pd.merge(summary, strats, on='generation') #merge datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#8 Regime identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Two regime classifications: based on top joint machine and based on percentage of play\n",
    "\n",
    "#By top joint machine:\n",
    "#Function to find the highest frequency percentage top machine\n",
    "def find_top_jm (df, n=1, column='freq_perc'):\n",
    "    return df.sort_index(by=column)[-n:]\n",
    "\n",
    "#Apply the function to get the highest frequency joint machine per generation\n",
    "topjm = freqjm.groupby('generation').apply(find_top_jm)\n",
    "\n",
    "#Define regime as the top joint machine in a generation if its frequency is above the defined \"regime_threshold\"\n",
    "#percentage. If none is above it, the regime is in \"other\"\n",
    "regime_threshold = 50 \n",
    "regime_jm = [jm if int(topjm.freq_perc[i]) > regime_threshold else 'not_threshold' for i,jm in enumerate(topjm.min_jms)]\n",
    "\n",
    "#Add regime to summary dataframe\n",
    "summary['regime_jm'] = regime_jm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#By percentage:\n",
    "regime_av = [None for i in summary.index] #Create variable to fill\n",
    "\n",
    "#Regime based on percetanges of machines playing AA or BB\n",
    "for i,row in summary.iterrows(): #all rows\n",
    "    A = row.coordination_A_perc\n",
    "    B = row.coordination_B_perc\n",
    "    if A > 0.8:\n",
    "        regime_av[i] = 'Domination_AA'\n",
    "    elif B > 0.8:\n",
    "        regime_av[i] = 'Domination_BB'\n",
    "    elif A > 0.35 and A < 0.55 and B > 0.35 and B < 0.55:\n",
    "        regime_av[i] = 'Turn_Taking'\n",
    "    elif A > 0.51 and A < 0.71 and B > 0.18 and B < 0.38:\n",
    "        regime_av[i] = 'Biased_Turn_A'\n",
    "    elif B > 0.51 and B < 0.71 and A > 0.18 and A < 0.38:\n",
    "        regime_av[i] = 'Biased_Turn_B'\n",
    "    else:\n",
    "        regime_av[i] = 'Other'\n",
    "        \n",
    "summary['regime_av'] = regime_av  \n",
    "#summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#9 Epoch characterization\n",
    "An epoch is defined as having the top joint machine on a generation (i.e. regime) to be the same over a window of \n",
    "past generations (e.g. was this period the same regime as in the past ones?). In that window of past regimes, some tolerance is permitted (i.e. some of them can be different, allowing for some errors).\n",
    "\n",
    "The algorithm considers an epoch to have started when a regime appears a minimum number of times in the window of past regimes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "epochs = pd.DataFrame(columns=['epoch','duration','start','end']) #to be filled with all epoch information\n",
    "#Parameters that can be changed\n",
    "epoch_window = 3 #lagged regimes to be considered\n",
    "epoch_tolerance = 1 #number of misses in the window before breaking an epoch\n",
    "\n",
    "switch = False #is there an epoch already started?\n",
    "length = 0 #of current epoch\n",
    "current_epoch = {'epoch': '', 'duration': 0, 'start': 0, 'end': 0}#will store info of each epoch\n",
    "\n",
    "for t,ep in enumerate(summary.regime_jm):#all generation (or regimes)\n",
    "    if t >= epoch_window: #intial observations not considered due to lagged window\n",
    "        lags = [summary.regime_jm[tt] for tt in xrange(t-epoch_window, t)] #window of past generations\n",
    "        \n",
    "        \n",
    "        #BEGIN:An epoch begins. This is when switch is False (no epoch has started) and epoch criteria is fulfilled\n",
    "        if lags.count(ep) >= (epoch_window-epoch_tolerance) and switch == False: #an epoch begins\n",
    "            switch = True\n",
    "            current_epoch['epoch'] = ep\n",
    "            length += 1\n",
    "            current_epoch['duration'] = length\n",
    "            current_epoch['start'] = t\n",
    "            #print 'begins ', current_epoch\n",
    "        \n",
    "        #CONTINUE:An epoch already is going, and criteria is met\n",
    "        elif lags.count(ep) >= (epoch_window-epoch_tolerance) and switch == True: #an epoch continues\n",
    "            length += 1\n",
    "            current_epoch['duration'] = length           \n",
    "            #print 'continues ', current_epoch\n",
    "        \n",
    "        \n",
    "        #END:An epoch is going, but criteria is not met. This could also mean there is an exception.\n",
    "        #An exception is a regime that shows up few times in a row (formally,less than the epoch_tolerance).\n",
    "        #The objective is that an exception doesn't end up and epoch. Initially, exceptions end them. However,\n",
    "        #This is dealt with later after the whole dataframe (epochs) is constructed.\n",
    "        elif lags.count(ep) < (epoch_window-epoch_tolerance) and switch == True:\n",
    "            current_epoch['end'] = t\n",
    "            index = len(epochs.index)\n",
    "            epochs.loc[index+1]=current_epoch\n",
    "            \n",
    "            switch = False #reset variables\n",
    "            length = 0\n",
    "            current_epoch = {'epoch': '', 'duration': 0, 'start': 0, 'end': 0}\n",
    "            #print 'end ', current_epoch\n",
    "\n",
    "        if t == len(summary.index)-1 and switch == True: #last generation that is not the end of an epoch\n",
    "            current_epoch['end'] = len(summary.index)\n",
    "            index = len(epochs.index)\n",
    "            epochs.loc[index+1]=current_epoch\n",
    "            \n",
    "        #print 'lags', lags\n",
    "    #print 'regime = ', ep,'\\n'\n",
    "    \n",
    "#Once 'epochs' is finished, handle the exceptions:\n",
    "#Take each row, and compare starting generation of an epoch with ending generation of the previous one.\n",
    "#If they are close enough (dictated by epoch_tolerance), join both epochs (rows) as a single one\n",
    "\n",
    "epochs_debug = copy.deepcopy(epochs)#capture for debugging before altering\n",
    "\n",
    "#Next part should be done in a while loop until no more changes are done\n",
    "for i in xrange(2, len(epochs.index)+1): #no zero position considered due to epochs starting at 1 (append coding)\n",
    "    regime_t = copy.deepcopy(epochs.epoch[i]) #variables from the dataframe to manipulate\n",
    "    regime_lag = copy.deepcopy(epochs.epoch[i-1])\n",
    "    end_t = copy.deepcopy(epochs.end[i])\n",
    "    start_t = copy.deepcopy(epochs.start[i])\n",
    "    end_lag = copy.deepcopy(epochs.end[i-1])\n",
    "    start_lag = copy.deepcopy(epochs.start[i-1])\n",
    "    \n",
    "    if regime_t == regime_lag and start_t-end_lag <= epoch_tolerance:#if considered as same epoch\n",
    "        epochs = epochs.drop(i-1)\n",
    "        epochs.loc[i, 'start'] = start_lag\n",
    "        epochs.loc[i, 'duration'] = end_t-start_lag #if end_t!=None else len(summary)-start_lag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#10 Export main dataframes\n",
    "Export the three main data frames, so I can work with graphs and statistics from a different file. This makes the scripts a bit more modular, and also I just have to run the minimization procedures (this file) only once per experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_file_modifier='deleteme' #To change the name of output file\n",
    "\n",
    "#Path to python outputs\n",
    "python_folder = \"/Users/luisalejandrolee/Dropbox/Thesis Phd/\\\n",
    "Coordination autos Chapter three/outputs_from_python/\" #Netlogo outputs in this folder\n",
    "\n",
    "#summary: contains main variables. Averages per generation\n",
    "summary.to_csv(python_folder+output_file_modifier+'summary_'+chosen_experiment)\n",
    "\n",
    "#freqjm: frequency of each joint machine per generation.\n",
    "freqjm.to_csv(python_folder+output_file_modifier+'jm_'+chosen_experiment)\n",
    "\n",
    "#epochs: each row has the regime (top joint machine if above threshold), start and end generation, and duration\n",
    "epochs.to_csv((python_folder+output_file_modifier+'epochs_'+chosen_experiment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#STOP! no need to run the script further\n",
    "###Just for visualization\n",
    "freqjm: frequency of all joint machines per generation (for transition analysis)\n",
    "\n",
    "summary: main variables (averages per generation)\n",
    "\n",
    "epochs: classification of epochs, with duration, starting and ending periods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#For visualization of joint machines with different frequency thresholds\n",
    "\n",
    "jm_freq_threshold = 0 #Change to higher for easier visualization (percentage)\n",
    "freqjm[freqjm.freq_perc > jm_freq_threshold] #keep machines with frequency higher than threshold\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
